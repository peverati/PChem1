% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={The Live Textbook of Physical Chemistry 1},
  pdfauthor={Dr.~Roberto Peverati},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{cancel}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{The Live Textbook of Physical Chemistry 1}
\author{\href{mailto:rpeverati@fit.edu}{Dr.~Roberto Peverati}}
\date{05 August 2020}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\begin{center}\includegraphics[width=0.8\linewidth]{./img/OEP_Figures.000} \end{center}

This textbook is the official textbook for the Physical Chemistry 1 Course (CHM 3001) at Florida Tech.

The instructor for this course and author of this textbook is Dr.~Roberto Peverati.

CONTACTS: \href{mailto:rpeverati@fit.edu}{\nolinkurl{rpeverati@fit.edu}}, Office: OPS 333, (321) 674-7735

Chemistry Program, Department of Biomedical and Chenical Engineering and Science
Florida Institute of Technology, Melbourne, FL.

\begin{quote}
This live open textbook is distributed under the \href{https://creativecommons.org/licenses/by-sa/4.0/}{CC-BY-SA 4.0 License} and it was funded by the Florida Tech Open Educational Resources Grant Program: A Collaboration of the Teaching Council, eEducation, and the Evans Library.
\end{quote}

\hypertarget{how-to-use-this-book}{%
\section*{How to use this book}\label{how-to-use-this-book}}
\addcontentsline{toc}{section}{How to use this book}

Please read this book carefully, since everything that will be in your exams is explained here.
Since this book is specifically tailored for the CHM 3001 course at Florida Tech, there are no superfluous parts. In other words, everything in it might be subject to question in the quizzes and the final exam.

\begin{quote}
Definitions and exercises are usually numbered and are highlighted in the text in this format (lighter grey, indented, and following a grey vertical bar). Please study the definitions carefully since they are fundamental concepts that will be used several times in the remainder of the text, and they will be subject to quizzes and exams. Exercises are essential for cementing the concepts, and you should attempt to execute them first without looking at the solution. Even if you were able to solve an exercise on your own, always read the solution after, since it might contain additional explanations expanding the main concepts in the text.
\end{quote}

Navigating the book should be straightforward. On each page, there is a useful sidebar on the left that gives you an overview of all chapters, and a toolbar at the top with important tools. Arrows to shift between chapters might also be present, depending on your browser. If you are old-school and prefer a pdf, you can download a printout by clicking on the toolbar's corresponding icon. If you are \emph{really} old-school and prefer a printed book, the best solution is to download the pdf and print it yourself. It is a LaTeX book, and I can promise you it will look good on paper. However, I cannot provide physical copies to each student. In the toolbar, you will find a useful search box that is capable of searching the entire book. The most adventurous will find in the toolbar a link to the raw GitHub source code. Feel free to head on \href{https://github.com/peverati/PChem1}{over there} and fork the book.

Each chapter of this book represents one week of work in the classroom and at home. The sidebar on the left will reflect your syllabus, as well as the main structure of the class on Canvas. The book is a live document, which means it will be updated throughout the semester with new material. While you are not required to check it every day, you might want to review each week's chapter before the lecture on Friday.

\begin{quote}
If you spot a mistake or a typo, contact Dr.~Peverati via \href{mailto:rpeverati@fit.edu}{email} and you will receive a credit of up to three points towards your final score, once the typo has been verified and corrected.
\end{quote}

\hypertarget{SystemVariables}{%
\chapter{Systems and Variables}\label{SystemVariables}}

\hypertarget{thermodynamic-systems}{%
\section{Thermodynamic Systems}\label{thermodynamic-systems}}

A thermodynamic system---or just simply a system---is a portion of space with defined boundaries that separate it from its surroundings (see also the title picture of this book). The surroundings may include other thermodynamic systems or physical systems that are not thermodynamic systems. A boundary may be a real physical barrier or a purely notional one. Typical examples of systems are reported in Figure \ref{fig:Fig1c1} below.\footnote{The photos depicted in this figure are taken from \href{https://en.wikipedia.org}{Wikipedia} and distributed under CC-BY-SA license.}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.001} 

}

\caption{Examples of Thermodynamic Systems}\label{fig:Fig1c1}
\end{figure}

In the first case, a liquid is contained in a typical Erlenmeyer flask. The boundaries of the system are the glass walls of the beaker. The second system is represented by the gas contained in a balloon. The boundary is a physical barrier also in this case, being the plastic of the balloon. The third case is that of a thunder cloud. The boundary is not a well-defined physical barrier, but rather some condition of pressure and chemical composition at the interface between the cloud and the atmosphere. Finally, the fourth case is the case of an open flame. In this case, the boundary is again non-physical, and possibly even harder to define than for a cloud. For example, we can choose to define the flame based on some temperature threshold, or some color criterion, or even some chemical one. Despite the lack of physical boundaries, both the cloud and the flame---as portions of space containing matter---can be defined as a thermodynamic system.

A system can exchange exclusively mass, exclusively energy, or both mass and energy with its surroundings. Depending on the boundaries' ability to exchange these quantities, a system is defined as open, closed, or isolated. An open system exchanges both mass and energy. A closed system exchanges only energy, but not mass. Finally, an isolated system does not exchange mass nor energy.

\begin{longtable}[]{@{}lcc@{}}
\toprule
\textbf{Type of System} & \textbf{Mass} & \textbf{Energy} (either heat or work)\tabularnewline
\midrule
\endhead
\textbf{Open} & Y & Y\tabularnewline
\textbf{Closed} & N & Y\tabularnewline
\textbf{Isolated} & N & N\tabularnewline
\bottomrule
\end{longtable}

When a system exchanges mass or energy with its surroundings, some of its parameters (variables) change. For example, if a system loses mass to the surroundings, the number of molecules (or moles) in the system will decrease. Similarly, if a system absorbs some energy, one or more of its variables (such as its temperature) increase. Mass and energy can flow into the system or out of the system. Let's consider mass exchange only. If some molecules of a substance leave the system, and then the same amount of molecules flow back into the system, the system will not be modified. We can count, for example, 100 molecules leaving a system and assign them the value of --100 in an outgoing process, and then observe the same 100 molecules going back into the system and assign them a value of +100. Regardless of the number of molecules present in the system in the first place, the overall balance will be --100 (from the outgoing process) +100 (from the ingoing process) = 0, which brings the system to its initial situation (mass has not changed). However, from a mathematical standpoint, we could have equally assigned the label +100 to the outgoing process and --100 to the ingoing one, and the overall total would have stayed the same: +100--100 = 0. Which of the two labels is best? For this case, it seems natural to define a mass going out of the system as negative (the system is losing it), and a mass going into the system as positive (the system is gaining it), but is it as straightforward for energy?

\begin{quote}
Here is another example. Let's consider a system that is composed of your body. When you exercise, you are losing mass in the form of water (sweat) and CO\textsubscript{2} (from respiration). This mass loss can be easily measured by stepping on a scale before and after exercise. The number you observe on the scale will go down. Hence you have lost weight. After exercise, you will reintegrate the lost mass by drinking and eating. If you have reintegrated the same amount you have lost, your weight will be the same as before the exercise (no weight loss). Nevertheless, which label do you attach to the amounts that you have lost and gained? Let's say that you are running a 5km race without drinking nor eating, and you measure your weight dropping 2 kg after the race. After the race, you drink 1.5 kg of water and eat a 500 g energy bar. Overall you did not lose any weight, and it would seem reasonable to label the 2 kg that you've lost as negative (--2) and the 1.5 kg of water that you drank and the 500 g bar that you ate as positive (+1.5 +0.5 = +2). But is it the only way? After all, you didn't gain nor lose any weight, so why not calling the 2 kg due to exercise +2 and the 2 that you've ingested as --2? It might seem silly, but mathematically it would not make any difference, the total would still be zero. Now, let's consider energy instead of mass. Let's say that in order to run the 5km race, you have spent 500 kcal, which then you reintegrate precisely by eating the energy bar. Which sign would you put in front of the kilocalories that you ``burned'' during the race? In principle, you've lost them, so if you want to be consistent, you should use a negative sign. But if you think about it, you've put quite an effort to ``lose'' those kilocalories, so it might not feel bad to assign them a positive sign instead. After all, it's perfectly OK to say, ``I've done a 500 kcal run today'', while it might sound quite awkward to say ``I've done a --500 kcal run today.'' Our previous exercise with mass demonstrates that it doesn't really matter which sign you put in front of the quantities. As long as you are consistent throughout the process, the signs will cancel out. If you've done a +500 kcal run, you've eaten a bar for --500 kcal, resulting in a total zero loss/gain. Alternatively, if you've done a --500 kcal run, you would have eaten a +500 kcal bar, for a total of again zero loss/gain.
\end{quote}

These simple examples demonstrate that the sign that we assign to quantities that flow through a boundary is arbitrary (i.e., we can define it any way we want, as long as we are always consistent with ourselves). There is no best way to assign those signs. If you ask two different people, you might obtain two different answers. But we are scientists, and we must make sure to be rigorous. For this reason, chemists have established a convention for the signs that we will follow throughout this course. If we are consistent in following the convention, we are guaranteed to never make any sign mistake.

\begin{quote}
\begin{definition}
\protect\hypertarget{def:chemistryconv}{}{\label{def:chemistryconv} }\emph{The chemistry convention of the sign is system-centric:}\footnote{Notice that physicists use a different sign convention when it comes to thermodynamics. To eliminate confusion, I will not describe the physics convention here, but if you are reading thermodynamics on a physics textbook, or if you are browsing the web and stumble on thermodynamics formula (e.g., on Wikipedia), please be advised that they might have a different sign than what is used in this course. Obviously, the science will not change, but you need to be ALWAYS consistent, so if you decide that you want to use the physics convention, make sure to ALWAYS use the physics convention. In this course, on the other hand, we will ALWAYS use the chemistry one, as introduced above.}

\begin{itemize}
\tightlist
\item
  \emph{If something (energy or mass) goes \textbf{into} the system it has a \textbf{positive} sign (the system is gaining)}
\item
  \emph{If something (energy or mass) goes \textbf{out of} the system it has a \textbf{negative} sign (the system is losing)}
\end{itemize}
\end{definition}
\end{quote}

If you want a trick to remember the convention, use the weight loss/gain during the exercise example above. You are the system, if you lose weight, the kilograms will be negative (--2 kg), while if you gain weight, they will be positive (+2 kg). Similarly, if you eat an energy bar, you are the system, and you will have increased your energy by +500 kcal (positive). In contrast, if you burned energy during exercise, you are the system, and you will have lost energy, hence --500 kcal (negative). If the system is a balloon filled with gas, and the balloon is losing mass, you are the balloon, and you are losing weight; hence the mass will be negative. If the balloon is absorbing heat (likely increasing its temperature and increasing its volume), you are the system, and you are gaining heat; hence heat will be positive.

\hypertarget{thermodynamic-variables}{%
\section{Thermodynamic Variables}\label{thermodynamic-variables}}

The system is defined and studied using parameters that are called variables. These variables are quantities that we can measure, such as pressure and temperature. However, they don't be surprised if, on some occasions, you encounter some variable that is a little harder to measure directly, such as entropy. The variables depend only on the current state of the system, and therefore they define it. If I know the values of all the ``relevant variables'' of a system, I know the state of the system. The relationship between the variables is described by mathematical functions called state functions, while the ``relevant variables'' are called natural variables.

What are the ``relevant variables'' of a system? The answer to this question depends on the system, and it is not always straightforward. The simplest case is the case of an ideal gas, for which the natural variables are those that enter the ideal gas law and the corresponding equation:

\begin{equation}
  PV=nRT       
  \label{eq:idealgaslaworiginal}
\end{equation}

Therefore, the natural variables for an ideal gas are the pressure P, the volume V, the number of moles n, and the temperature T, with R being the ideal gas constant. Recalling from the general chemistry courses, R is a universal dimensional constant which has the values of R = 8.31 kJ/mol in SI units.\\
We will use the ideal gas equation and its variables as an example to discuss variables and functions in this chapter. We will analyze more complicated cases in the next chapters.
Variables can be classified according to numerous criteria, each with its advantages and disadvantages. A typical classification is:

\begin{itemize}
\tightlist
\item
  \textbf{Physical variables} (\(P\), \(V\), \(T\) in the ideal gas law): independent on the chemical composition of the system.
\item
  \textbf{Chemical variables} (\(n\) in the ideal gas law): dependent on the chemical composition of the system.
\end{itemize}

Another useful classification is:

\begin{itemize}
\tightlist
\item
  \textbf{Intensive variables} (\(P\), \(T\) in the ideal gas law): independent on the physical size (extension) of the system.
\item
  \textbf{Extensive variables} (\(V\), \(n\) in the ideal gas law): dependent on the physical size (extension) of the system.
\end{itemize}

When we deal with thermodynamic systems, it is more convenient to work with intensive variables. Luckily, it is relatively easy to convert extensive variables into intensive ones by just taking the ratio between two of them. For an ideal gas, by taking the ratio between V and n, we obtained the intensive variable called molar volume:

\begin{equation}
  V_m=\frac{V}{n}.   
  \label{eq:Vmdef}
\end{equation}

We can then recast eq. \eqref{eq:idealgaslaworiginal} as:

\begin{equation}
  PV_m=RT,
  \label{eq:idealgaslaw}
\end{equation}

which is the preferred equation that we will use for the remainder of this course.
The ideal gas equation connects the 3 variables pressure, molar volume, and temperature, and reduces the number of independent variables to just 2. In other words, once 2 of the 3 variables are known, the other one can be easily obtained using these simple relations:

\begin{equation}
  P(T,V_m)=\frac{RT}{V_m},
  \label{eq:PTVm}
\end{equation}

\begin{equation}
  V_m(T,P)=\frac{RT}{P},
  \label{eq:VmTP}
 \end{equation}

\begin{equation}
  T(P,V_m)=\frac{PV_m}{R}.
  \label{eq:TPVm}
\end{equation}

These equations define three state functions, each one expressed in terms of two independent natural variables. For example, eq. \eqref{eq:PTVm} defines the state function called ``pressure'', expressed as a function of temperature and molar volume. Similarly, eq. \eqref{eq:VmTP} defines the ``molar volume'' as a function of temperature and pressure, and eq. \eqref{eq:TPVm} defines the ``temperature'' as a function of pressure and molar volume. When we know the natural variables that define a state function, we can express the function using its total differential, for example for the pressure \(P(T, V_m)\):

\begin{equation}
  dP=\left( \frac{\partial P}{\partial T} \right)dT + \left( \frac{\partial P}{\partial V_m} \right)dV_m
  \label{eq:totaldifferentialP}
\end{equation}

Recalling Schwartz's theorem, the mixed partial second derivatives that can be obtained from eq. 1.2.7 are the same:

\begin{equation}
  \frac{\partial^2 P}{\partial T \partial V_m}=\frac{\partial}{\partial V_m}\frac{\partial P}{\partial T}=\frac{\partial}{\partial T}\frac{\partial P}{\partial V_M}=\frac{\partial^2 P}{\partial V_m \partial T}
  \label{eq:schwartzP}
\end{equation}

Which can be easily verified considering that:

\begin{equation}
  \frac{\partial}{\partial V_m} \frac{\partial P}{\partial T}  = \frac{\partial}{\partial V_m} \left(\frac{R}{V_m}\right) = -\frac{R}{V_m^2} 
  \label{eq:secondderPA}
\end{equation}

and

\begin{equation}
  \frac{\partial}{\partial T} \frac{\partial P}{\partial V_m}  = \frac{\partial}{\partial T} \left(\frac{-RT}{V_m^2}\right) = -\frac{R}{V_m^2} 
  \label{eq:secondderPB}
\end{equation}

While for the ideal gas law, all the variables are ``well-behaved'' and always satisfy Schwartz's theorem, we will encounter some variable for which Schwartz's theorem does not hold. Mathematically, if the Schwartz's theorem is violated (i.e., if the mixed second derivatives are not equal), then the corresponding function cannot be integrated, hence it is not a state function. The differential of a function that cannot be integrated cannot be defined exactly. Thus, these functions are called path functions; that is, they depend on the path rather than the state. The most typical example of path functions that we will encounter in the next chapters are heat (Q) and work (W). For these functions, we cannot define exact differentials \(dQ\) and \(dW\), and we must introduce a new notation to define their ``inexact differentials'' \(đ Q\) and \(đ W\).

\begin{quote}
We will return on exact and inexact differential when we discuss heat and work, but for this chapter, it is important to notice the difference between a state function and a path function. A typical example to understand the difference between state and path function is to consider the distance between two geographical locations. Let's, for example, consider the distance between New York City and Los Angeles. If we fly straight from one city to the other, there are roughly 4,000 km between them. This ``air distance'' depends exclusively on the geographical location of the two cities. It stays constant regardless of the method of transportation that I have accessibility to travel between them. Since the cities' positions depend uniquely on their latitudes and longitudes, the ``air distance'' is a state function, i.e., it is uniquely defined from a simple relationship between measurable variables. However, the ``air distance'' is not the distance that I will practically have to drive when I go from NYC to LA. Such ``travel distance'' depends on the method of transportation that I decide to take (airplane vs.~car vs.~train vs.~boat vs.~\ldots). It will depend on a plentiful amount of other factors such as the choice of road to be traveled (if going by car), the atmospheric conditions (if flying), and so on. A typical ``travel distance'' by car is, for example, about 4,500 km, which is about 12\% more than the ``air distance.'' Certainly, we could even design a very inefficient road trip that avoids all highways and will result in a ``travel distance'' of 8,000 km or even more (200\% of the ``air distance''). The ``travel distance'' is a clear example of a path function because it depends on the specific path that I decide to travel to go from NYC to LA. See Figure \ref{fig:Fig2c1}.
\end{quote}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.002} 

}

\caption{State Functions vs. Path Functions}\label{fig:Fig2c1}
\end{figure}

\hypertarget{ZerothLaw}{%
\chapter{Zeroth Law of Thermodynamics}\label{ZerothLaw}}

\hypertarget{what-is-thermodynamics}{%
\section{What is Thermodynamics?}\label{what-is-thermodynamics}}

Thermodynamics is the branch of science that deals with heat and work, and their relation to energy. As the definition suggests, thermodynamics is concerned with two types of energy: heat and work. A definition of these forms of energy is as follow:

\begin{itemize}
\tightlist
\item
  Work is exchanged if external parameters are changed during the process.
\item
  Heat is exchanged if only internal parameters are changed during the process.
\end{itemize}

As we saw in Chapter \ref{SystemVariables} though, heat and work are not ``well-behaved'' quantities because they are path functions. While on the one hand it might be simple to measure experimentally the amount of heat and/or work, these measured numbers cannot be used to define the state of a system. Since heat and work are path functions, their values depend directly on the methods that are used to transfer them (their paths). Understanding and quantifying these energy transfers is the reason why thermodynamics was developed in the first place. The origin of thermodynamics dates back to the seventeenth century, a time when people began to use heat and work for technological applications. These early scientists needed a mathematical tool to understand how heat and work were related with each other, and how they were also related with the other variables that they were able to measure, such as temperature and volume.

Before we even discuss the definition of energy and how it relates to heat and work, it is important to introduce the important concept of temperature. Temperature is an intuitive concept that has a surprisingly complex definition. In fact with this course we will not even arrive at a rigorous definition of temperature, so you will not see it in this book. However, for all our purposes, it is not important to have a microscopic definition of temperature, as long as we have guarantee that this quantity can be measured in an unambiguous manner. In other words, we need a mathematical definition of temperature that will agree with the physical existence of thermometers.

\hypertarget{the-zeroth-law-of-thermodynamics}{%
\section{The Zeroth Law of Thermodynamics}\label{the-zeroth-law-of-thermodynamics}}

The mathematical definition that guaranteer that the thermal equilibrium is an equivalence relation is called the zeroth law of thermodynamics. The zeroth law of thermodynamics states that if two thermodynamic systems are each in thermal equilibrium with a third one, then they are in thermal equilibrium with each other. The law might appear trivial and possibly superfluous, but it is a fundamental requirement for the mathematical formulation of thermodynamics, so it needs to be stated. The zeroth law can be summarized by the following simple mathematical relation:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:zerothlaw}{}{\label{def:zerothlaw} }\emph{Zeroth Law of Thermodynamics:} If \(T_A = T_B\), and \(T_B = T_C\), then \(T_A = T_C\).
\end{definition}
\end{quote}

Notice that when we state the zeroth law, it appears intuitive. However, this is not necessarily the case. Let's, for example, consider a pot of boiling water at \(P=\) 1 atm. Its temperature, \(T_{H_2O}\), is about 373 K. Let's now immerse in this water a coin made of wood and another coin made of metal. After some sufficient time, the wood coin will be in thermal equilibrium with the water, and its temperature \(T_W = T_{H_2O}\). Similarly, the metal coin will also be in thermal equilibrium with the water, hence \(T_M = T_{H_2O}\). According to the zeroth law the temperature of the wood coin and that of the metal coin are exactly the same \(T_W = T_M\), even if they are not in direct contact with each other. Now here's the catch: since wood and metal transmit heat in different manners, if I take the coins out of the water and put them immediately in your hands, one of them will be very hot, but the other will burn you. So, if you had to guess the temperature of the two coins without a thermometer, and without knowing that they were immersed in boiling water, would you guess that they have the same temperature? Probably not.

\hypertarget{workint}{%
\section{Calculation of Work}\label{workint}}

In thermodynamics, work (\(W\)) is the ability of a system to transfer energy by exerting a force on its surroundings. Work can be measured simply by evaluating its effects, such as displacing a massive object by some amount of space. The mathematical treatment of work, however, is complicated because \emph{work is a path function}. In the following sections, we will analyze how work is calculated in some prototypical situations commonly encountered in the thermodynamical treatment of systems.

\hypertarget{free-expansion-at-constant-temperature}{%
\subsection{Free expansion at constant temperature}\label{free-expansion-at-constant-temperature}}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./img/OEP_Figures.003} 

}

\caption{Free Expansion at Constant Temperature of an Ideal Gas}\label{fig:Fig1c3}
\end{figure}

Let's consider the situation in Figure \ref{fig:Fig1c3}, where a special beaker with a piston that is free to move is filled with an ideal gas. The beaker sits in a horizontal position on a desk, so the piston is not subject to any external forces\footnote{For this simple thought experiment, we will ignore any external force that is not significant. In other words, we will not consider the friction of the piston on the beaker walls or any other foreign influence.}. The piston is initially compressed to a position that is not in equilibrium \((i)\). After the process, the piston reaches a final equilibrium position \((f)\). We assume that the only force acting on the piston is the pressure of the ideal gas, \(P\). How do we calculate the work (\(W\)) performed by the system?

From basic physics, we recall that the infinitesimal amount of work associated with an object moving in space is given by the force acting on the object (\(F\)) multiplied by the infinitesimal amount it gets displaced (\(d h\)):

\begin{equation}
  đ W = - Fdh,
  \label{eq:Wphysics}
\end{equation}

where the negative sign comes from the chemistry sign convention, Definition \ref{def:chemistryconv}, since the work in Figure \ref{fig:Fig1c3} is \emph{performed} by the system (expansion). What kind of force is moving the piston? It is the force due to the pressure of the gas. Relying upon another definition from physics, pressure is the ratio between the force (\(F\)) and the area (\(A\)) that such force acts upon:

\begin{equation}
  P = F/A.
  \label{eq:Pphysics}
\end{equation}

Obtaining \(F\) from eq. \eqref{eq:Pphysics} and replacing it in eq. \eqref{eq:Wphysics}, we obtain:

\begin{equation}
  đ W = - P \underbrace{Adh}_{dV},
  \label{eq:Wphysics2}
\end{equation}

and considering that \(Adh\) (area times infinitesimal height) is the definition of an infinitesimal volume \(dV\), we obtain:

\begin{equation}
  đ W = - PdV,
  \label{eq:Wdef}
\end{equation}

If we want to calculate the amount of work performed by a system, \(W\), from eq. \eqref{eq:Wdef}, we need to recall that \(đ W\) is an inexact differential. As such, we cannot integrate it from initial to final as for the (exact) differential of a state function, because:

\begin{equation}
  \int_{i}^{f}đ W \neq W_f - W_i,
  \label{eq:Wdiff}
\end{equation}

but rather:

\begin{equation}
  \int_{\text{path}} đ W = W,
  \label{eq:Wdiff2}
\end{equation}

where the integration is performed along the \emph{path}. Using eq. \eqref{eq:Wdiff2}, we can integrate eq. \eqref{eq:Wdef} as:

\begin{equation}
  \int đ W = W = - \int_{i}^{f} PdV,
  \label{eq:Wint}
\end{equation}

where the integral on the left-hand side is taken along the path,\footnote{from here on we will replace the notation \(\int_{\text{path}}\) with the more convenient \(\int\) and we will keep in mind that the integral of an inexact differential must be taken along the path.} while the integral on the right-hand side can be taken between the initial and final states, since \(dV\) is a state function.
How do we solve the integral in eq. \eqref{eq:Wint}? The pressure in this process is not constant since it decreases throughout the process. Therefore \(P\) cannot be moved outside the integral. However, if our gas is ideal, we can calculate the pressure using the ideal gas law \(P=\frac{nRT}{V}\), and solve the integral because \(n\), \(R\), and \(T\) are constant:

\begin{equation}
  W = - nRT \int_{i}^{f} \frac{dV}{V} = -nRT \ln \frac{V_f}{V_i},
  \label{eq:WintsolvedV}
\end{equation}

which, considering that \(P_iV_i=P_fV_f\), can be also written as:

\begin{equation}
  W = -nRT \ln \frac{P_i}{P_f}.
  \label{eq:WintsolvedP}
\end{equation}

\hypertarget{isothermal-expansion-against-a-constant-external-pressure}{%
\subsection{Isothermal expansion against a constant external pressure}\label{isothermal-expansion-against-a-constant-external-pressure}}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./img/OEP_Figures.004} 

}

\caption{Isothermal Expansion of an Ideal Gas Against a Constant External Pressure}\label{fig:Fig2c3}
\end{figure}

The process that we are analyzing here (Figure \ref{fig:Fig2c3}) is apparently similar to the case we have seen in the previous section, with the noticeably difference that the beaker now sits vertically on the workbench. For this case, when the piston moves upwards, it is no longer moving freely, but it moves against the force due to the constant external pressure \(P_{\text{ext}}\).

The integral that describes the work performed by the system in this case involves a transformation at constant external pressure:

\begin{equation}
  \int đ W = W = - \int_{i}^{f} P_{\text{ext}}dV,
  \label{eq:Wint2}
\end{equation}

which can be easily simplified as:

\begin{equation}
  W = - \int_{i}^{f} P_{\text{ext}}dV = -P_{\text{ext}} \int_{i}^{f} dV = -P_{\text{ext}} (V_f-V_i),
  \label{eq:Wint3}
\end{equation}

resulting in the following simple formula to calculate \(W\):

\begin{equation}
  W = -P_{\text{ext}} \Delta V,
  \label{eq:WintF}
\end{equation}

Comparing eq. \eqref{eq:WintF} with eq. \eqref{eq:WintsolvedP} shows how different this case is from the previous one.

\hypertarget{heatint}{%
\section{Calculation of Heat}\label{heatint}}

Heat (\(Q\)) is a property that gets transferred between substances. Similarly to work, the amount of heat that flows through a boundary can be measured, but its mathematical treatment is complicated because \emph{heat is a path function}.
As you probably recall from general chemistry, the ability of a substance to absorb heat is given by a coefficient called the heat capacity, which is measured in SI in \(\frac{\text{J}}{\text{mol K}}\). However, since heat is a path function, these coefficients are not unique, and we have different ones depending on how the heat transfer happens.

\hypertarget{processes-at-constant-volume-isochoric}{%
\subsection{Processes at constant volume (isochoric)}\label{processes-at-constant-volume-isochoric}}

The heat capacity at constant volume measures the ability of a substance to absorb heat at constant volume. Recasting from general chemistry:

\begin{quote}
The molar heat capacity at constant volume is the amount of heat required to increase the temperature of 1 mol of a substance by 1 K at constant volume.
\end{quote}

This simple definition can be written in mathematical terms as:

\begin{equation}
  C_V = \frac{đ Q_V}{n dT} \Rightarrow đ Q_V = n C_V dT.
  \label{eq:Cvdef}
\end{equation}

Given a known value of \(C_V\), the amount of heat that gets transfered can be easily calculated by measuring the changes in temperature, after integration of eq. \eqref{eq:Cvdef}:

\begin{equation}
  đ Q_V = n C_V dT \rightarrow \int đ Q_V = n \int_{T_i}^{T_F}C_V dT \rightarrow Q_V = n C_V \int_{T_i}^{T_F}dT,
  \label{eq:Cvint1}
\end{equation}

which, assuming \(C_V\) independent of temperature, simply becomes:

\begin{equation}
  Q_V \cong n C_V \Delta T.
  \label{eq:Cvint}
\end{equation}

\hypertarget{heatconstp}{%
\subsection{Processes at constant pressure (isobaric)}\label{heatconstp}}

Similarly to the previous case, the heat capacity at constant pressure measures the ability of a substance to absorb heat at constant pressure. Recasting again from general chemistry:

\begin{quote}
The molar heat capacity at constant pressure is the amount of heat required to increase the temperature of 1 mol of a substance by 1 K at constant pressure.
\end{quote}

And once again, this mathematical treatment follows:

\begin{equation}
  C_P = \frac{đ Q_P}{n dT} \Rightarrow đ Q_P = n C_P dT \rightarrow \int đ Q_P = n \int_{T_i}^{T_F}C_P dT,
  \label{eq:Cpdef}
\end{equation}

which result in the simple formula:

\begin{equation}
  Q_P \cong n C_P \Delta T.
  \label{eq:Cpint}
\end{equation}

\hypertarget{FirstLaw}{%
\chapter{First Law of Thermodynamics}\label{FirstLaw}}

\hypertarget{energyint}{%
\section{Calculation of Internal Energy Changes}\label{energyint}}

The internal energy (\(U\)) of a system is a thermodynamic state function defined as:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:energy}{}{\label{def:energy} }\emph{Internal Energy:} Property of a system that can be wither transferred or converted.
\end{definition}
\end{quote}

In the absence of chemical transformations, heat and work are the only two forms of energy that thermodynamics is concerned with. Keeping in mind Definition \ref{def:chemistryconv}, which gives the convention for the signs of heat and work, the internal energy of a system can be written as:

\begin{equation}
  U = Q + W,
  \label{eq:U}
\end{equation}

which we can write in differential form by considering that the internal energy is a state function, as:
\begin{equation}
  dU = đ Q + đ W,
  \label{eq:dU}
\end{equation}

which, using eq. \eqref{eq:Wdef} becomes:

\begin{equation}
  dU = đ Q - PdV.
  \label{eq:dUpdv}
\end{equation}

\hypertarget{isothermalE}{%
\subsection{Internal energy in isothermal processes}\label{isothermalE}}

To study the behavior of the internal energy in a process at constant temperature (\(dT=0\)), James Prescott Joule (1818--1889) created the apparatus depicted in Figure \ref{fig:FigJexp}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.006} 

}

\caption{The Joule Expansion Experiment.}\label{fig:FigJexp}
\end{figure}

The left side of the Joule apparatus's inner chamber is filled with an ideal gas, while a vacuum is created in the right chamber. Both chambers are immersed in a water bath, to guarantee isolation from the environment. When the communication channel between the chambers is open, the gas expands and equilibrates. The work associated with the transformation is:

\begin{equation}
  đ W=P_{\text{ext}}dV = 0,
  \label{eq:JexpW}
\end{equation}

since the chambers are not in communication with the environment, \(P_{\text{ext}}=0\). Thus, changes in internal energy are associated with the heat transfer of the process, which can be measured by monitoring the temperature of the gas at the beginning, \(T_i\), and at the end of the experiment \(T_f\). Joule noticed experimentally that if he used an ideal gas for this experiment, the temperature will not change \(T_i = T_f\). Since the temperature doesn't change there is no heat transfer, and therefore the internal energy stays constant:

\begin{equation}
  dU = đ Q = 0.
  \label{eq:JexpQU}
\end{equation}

\begin{quote}
Notice that Joule's conclusion is valid only for an ideal gas. If we expand a real gas we do notice a change in temperature associated with the expansion. A typical example of this behavior is when you use a pressurized spray bottle and release its content for an extended time in the air. The container will typically get colder. We will discuss this behavior in a following chapter when we will study real gases.
\end{quote}

From this simple experiment, we can conclude that the internal energy of an ideal gas depends only on its temperature.

\hypertarget{internal-energy-in-adiabatic-processes}{%
\subsection{Internal energy in adiabatic processes}\label{internal-energy-in-adiabatic-processes}}

An adiabatic process is defined as a process that happens without the exchange of heat. As such, \(đ Q=0\), and the work associated with an adiabatic process becomes a state function:

\begin{equation}
  dU=đ W=PdV,
  \label{eq:dUadiabatic}
\end{equation}

which can then be calculated using the formulas that we derived in section \ref{workint}. Notice that isothermal and adiabatic are two very different processes. While an adiabatic process happens without the exchange of heat across the system's boundaries, this does not mean that the system's temperature does not change. Isothermal processes are usually associated with a heat transfer across the boundaries to maintain the temperature of the system constant. For adiabatic processes, it is quite the opposite since they are usually associated with a change in temperature.

\hypertarget{internal-energy-in-isochoric-processes}{%
\subsection{Internal energy in isochoric processes}\label{internal-energy-in-isochoric-processes}}

An isocoric process is a process in which the volume does not change. Therefore, \(đ W=0\), and \(dU = đ Q_V\), which for 1 mol of substance and using eq. \eqref{eq:Cvdef}, becomes:

\begin{equation}
  dU = đ Q_V = n C_V dT.
  \label{eq:dUqv}
\end{equation}

Since no work is performed at these conditions, the heat becomes a state function. Eq. \eqref{eq:dUqv} also gives a mathematical justification of the concept of heat capacity at constant volume. \(C_V\) can now be interpreted as the partial derivative (a coefficient) of a state function (the internal energy):

\begin{equation}
  C_V = \left( \frac{\partial U} {\partial T} \right)_{V,n},
  \label{eq:cvstatefunc}
\end{equation}

where we have replaced the total derivative \(d\) with a partial one \(\partial\), and we have specified that the derivation happens at constant volume and number of moles. Eq. \eqref{eq:cvstatefunc} equation brings a rigorous definition of heat capacity at constant volume for 1 mol of substance:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:newdefcv}{}{\label{def:newdefcv} }\emph{The heat capacity of a substance, \(C_V\), represents its ability to absorb \textbf{energy} at constant \textbf{volume}.}
\end{definition}
\end{quote}

\hypertarget{enthalpy}{%
\subsection{Internal energy in isobaric processes}\label{enthalpy}}

In an isobaric process, the pressure does not change, hence \(dP=0\). Unfortunately, eq. \eqref{eq:dU} for this case does not simplify further, as happened in the two previous cases. However, in section \ref{heatconstp}, we have introduced the useful concept of heat capacity at constant \(P\). \(C_P\) was used in an adiabatic process in the same manner as \(C_V\) was used in the isochoric case. That is, as a coefficient to measure the amount of heat absorbed at constant pressure. Eq. \eqref{eq:cvstatefunc} gave a mathematical definition of \(C_V\) as the partial derivative of a state function (the internal energy). But if heat capacities are coefficients, and coefficients are partial derivatives of state functions, how do we explain \(C_V\)?

In order to do so, we can introduce a new state function, called the enthalpy (\(H\)), as:

\begin{equation}
  H = U + PV,
  \label{eq:enthalpydef}
\end{equation}

and its differential, calculated as:

\begin{equation}
  dH = dU + d(PV) = dU + PdV + \overbrace{VdP}^{0},
  \label{eq:enthalpydefdiff}
\end{equation}

which can be rearranged as:

\begin{equation}
  dU = dH -PdV,
  \label{eq:enthalpydefdiffu}
\end{equation}

Replacing eq. \eqref{eq:enthalpydefdiffu} into eq. \eqref{eq:dUpdv}:

\begin{equation}
  dH -PdV = đ Q_P - PdV,
  \label{eq:dh1}
\end{equation}

which simplifies to:

\begin{equation}
  dH = đ Q_P.
  \label{eq:dh2}
\end{equation}

Eq. \eqref{eq:dh2} establishes that the heat exchanged at constant pressure is equal to a new state function called the enthalpy, defined by eq. \eqref{eq:enthalpydef}. It also establishes a mathematical justification of the concept of heat capacity at constant pressure. Similarly to \(C_V\), \(C_P\) can now be interpreted as the partial derivative (a coefficient) of the new state function (the enthalpy):

\begin{equation}
  C_P = \left( \frac{\partial H} {\partial T} \right)_{P,n},
  \label{eq:cpstatefunc}
\end{equation}

Eq. \eqref{eq:cpstatefunc} brings also a rigorous definition of heat capacity at constant pressure for 1 mol of substance:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:newdefcp}{}{\label{def:newdefcp} }\emph{The heat capacity of a substance, \(C_P\), represents its ability to absorb \textbf{enthalpy} at constant \textbf{pressure}.}
\end{definition}
\end{quote}

\hypertarget{the-first-law-of-thermodynamics}{%
\section{The First Law of Thermodynamics}\label{the-first-law-of-thermodynamics}}

We finally come to a working definition of the first law. If we take an isolated system---i.e., a system that does not exchange heat nor mass with its surroundings---its internal energy is conserved. If the internal energy is conserved, \(dU=0\). Therefore, for an isolated system:

\begin{equation}
  đ Q = -đ W,
  \label{eq:heateqwork}
\end{equation}

and heat and work can be easily calculated using any of the appropriate formulas introduced in either Section \ref{workint} or \ref{heatint}.

The first law is a conservation law. It is intuitive since it comes directly from Lavoisier's principle of ``nothing is lost, nothing is created, everything is transformed.'' Considering that the only system that is truly isolated is the universe, we can condense the first law in one simple sentence:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:firstlaw}{}{\label{def:firstlaw} }\emph{First Law of Thermodynamics:} The energy of the universe is conserved.
\end{definition}
\end{quote}

\hypertarget{reversible-and-irreversible-processes}{%
\section{Reversible and Irreversible processes}\label{reversible-and-irreversible-processes}}

\hypertarget{calculation-of-w_textmax-and-w_textmin}{%
\subsection{\texorpdfstring{Calculation of \(| W_{\text{max}} |\) and \(| W_{\text{min}} |\)}{Calculation of \textbar{} W\_\{\textbackslash text\{max\}\} \textbar{} and \textbar{} W\_\{\textbackslash text\{min\}\} \textbar{}}}\label{calculation-of-w_textmax-and-w_textmin}}

Let's go back to the calculation of the work in a process at constant temperature. We can use the formulas obtained in section \ref{workint} to understand a little bit better the meaning of a \emph{path function}. Let's consider the following PV diagram, obtained from an ideal gas at constant \(T=298\) K:

\begin{center}\includegraphics{pchem1_files/figure-latex/unnamed-chunk-2-1} \end{center}

where the isothermal expansion happens between \(P_i\) and \(P_f\). If the expansion happens in a one-step fast process, for example against a constant pressure \(P_f=P_{\text{ext}}\), the work is given by eq. \eqref{eq:WintF}. On the plot, the absolute value of the work\footnote{we use the absolute value to avoid confusions due to the fact that the expansion work is negative according to Definition \ref{def:chemistryconv}.} is represented by the red area:

\begin{center}\includegraphics{pchem1_files/figure-latex/unnamed-chunk-3-1} \end{center}

\begin{equation}
\left| W_{\text{1-step}} \right| = P_{\text{ext}} (V_f-V_i)
  \label{eq:Warea1}
\end{equation}

However, if the process happens in two steps, by pausing at position (1) until equilibrium is reached, then we should calculate the work by dividing the process into two. The first process is an expansion between \(P\) and \(P_1\), whose absolute value of the work, \(W_A\), is represented by the blue area:

\begin{center}\includegraphics{pchem1_files/figure-latex/unnamed-chunk-4-1} \end{center}

\begin{equation}
\left| W_A \right| = P_1 (V_1-V_i)
  \label{eq:Warea2}
\end{equation}

The second process is an expansion between \(P_1\) and \(P_{\text{ext}}\), whose absolute value of the work is represented by the green area:

\begin{center}\includegraphics{pchem1_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{equation}
\left| W_B \right| = P_f (V_f-V_1)
  \label{eq:Warea3}
\end{equation}

The total absolute value of the work for the 2-step process is given by the sum of the two areas:

\begin{center}\includegraphics{pchem1_files/figure-latex/unnamed-chunk-6-1} \end{center}

\begin{equation}
  \left| W_{\text{2-step}} \right| = \left| W_A \right| + \left| W_B \right| = P_1 (V_1-V_i)+P_f (V_f-V_1).
  \label{eq:Warea4}
\end{equation}

As can be easily verified by comparing the shaded areas in the plots, \(\left| W_{\text{2-step}} \right| > \left| W_{\text{1-step}} \right|\).

We can easily extend this procedure to consider processes that happens in 3, 4, 5, \ldots, \(n\) steps. What is the limit of this procedure? In other words, what happens when \(n \rightarrow \infty\)? A simple answer is given by the plots in the next Figure, which clearly demonstrates that the maximum value of the area underneath the curve \(\left| W_{\text{max}}\right|\) is achieved in an \(\infty\)-step process, for which the work is calculated as:

\begin{equation}
  \left| W_{\infty \text{-step}} \right| = \left| W_{\text{max}} \right| = \sum_{n}^{\infty} P_n(V_n-V_{n-1}) = \int_{i}^{f} PdV.
  \label{eq:WintsolvedV2}
\end{equation}

\includegraphics[width=0.5\linewidth,height=1\textheight]{pchem1_files/figure-latex/figures-side-1} \includegraphics[width=0.5\linewidth,height=1\textheight]{pchem1_files/figure-latex/figures-side-2} \includegraphics[width=0.5\linewidth,height=1\textheight]{pchem1_files/figure-latex/figures-side-3} \includegraphics[width=0.5\linewidth,height=1\textheight]{pchem1_files/figure-latex/figures-side-4}

The integral on the right hand side of eq. \eqref{eq:WintsolvedV2} is similar to the integral that we already solved for eq. \eqref{eq:WintsolvedV}. Using the same trick, we can solve eq. \eqref{eq:WintsolvedV2} for an ideal gas as:

\begin{equation}
  \left| W_{\text{max}} \right| = nRT \int_{i}^{f} \frac{dV}{V} = nRT \ln \frac{V_f}{V_i}.
  \label{eq:WmaxV}
\end{equation}

This example shows clearly why work is a path function. If we perform a fast 1-step expansion the system will perform an amount of work that is much smaller than the amount of work it can perform if the expansion between the same points happens slowly in an \(\infty\)-step process.

The same considerations that we made up to this point for expansion processes hold specularly for compression ones. The only difference is that the work associated with compressions will have a positive sign since it must be performed onto the system. As such, the amount of work for a transformation that happens in a finite amount of steps will be an upper bound to the minimum amount of work required to compress the system.\footnote{In contrast to a lower bound for expansion processes.} \(\left| W_{\text{min}} \right|\) for compressions is calculated as the area underneath the PV curve, exactly as \(\left| W_{\text{min}} \right|\) for expansions in eq. \eqref{eq:WintsolvedV2}.

\hypertarget{cycles-and-reversibility}{%
\subsection{Cycles and reversibility}\label{cycles-and-reversibility}}

Let's now consider the cycle in Figure \ref{fig:FigRevCyc}. The process in this case starts from state 1 (system at \(P_1V_1\)), expands to state 2 (system at \(P_2V_2\)), and compresses back to state 1 (system back to \(P_1V_1\)).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.005} 

}

\caption{Expansion/Compression Cycle of an Ideal Gas}\label{fig:FigRevCyc}
\end{figure}

Since the process starts and finishes at the same state, the value of the internal energy at the end of the process will be the same as its value at the beginning, regardless of the path:\footnote{recall that the internal energy is a state function, so its value depend exclusively from the conditions at the beginning and at the end. In a cycle we're going back to the same point, so the conditions at the beginning and at the end are equal by definition.}

\begin{equation}
  \oint dU=0,
  \label{eq:de0}
\end{equation}

where the symbol \(\oint\) indicates an integral around a cycle. Considering the work associated with the cycle, however, the situation is radically different because it depends on the path that the system is taking, and in general
\begin{equation}
\oint_{\text{path}} đW \neq 0.
  \label{eq:dw0}
\end{equation}

For instance, if we perform the expansion in one step, the work associated with it will be (using eq. \eqref{eq:WintF}):\footnote{notice that the work for the expansion is negative, as it should be.}

\begin{equation}
  W^{\text{expansion}}_{\text{1-step}}=-P_2(\underbrace{V_2-V_1}_{>0})<0,
  \label{eq:Wexp1}
\end{equation}

and if we also perform the compression in 1-step:\footnote{notice that the work for the compression is positive, as it should be.}

\begin{equation}
  W^{\text{compression}}_{\text{1-step}}=-P_1(\underbrace{V_2-V_1}_{<0})>0.
  \label{eq:Wcomp1}
\end{equation}

With a little bit of math, it is easy to prove that the total work for the entire cycle is:

\begin{equation}
\begin{aligned}
W^{\text{cycle}}_{\text{1-step}} {} & =  W^{\text{expansion}}_{\text{1-step}}+W^{\text{compression}}_{\text{1-step}} \\
 & = -P_2(V_2-V_1)-P_1(V_1-V_2) \\
 & = -P_2(V_2-V_1)+P_1(V_2-V_1) \\
 & = (\underbrace{V_2-V_1}_{>0})(\underbrace{P_1-P_2}_{>0}) > 0,
\end{aligned}
  \label{eq:Wtot1}
\end{equation}

or, in other words, net work is destroyed.

\begin{quote}
In practice, if we want to manually perform this cycle by pushing on the piston by hand, we will notice that it requires more energy to push down than the amount it gives back when we release it and it moves back up.
\end{quote}

In contrast, if both the expansion and the compression happen in a slow \(\infty\)-step manner, the work associated with them will be \(W_{\text{max}}\) and \(W_{\text{min}}\), respectively, which are calculated using eq. \eqref{eq:WmaxV}. The total work related with the cycle will be in this case:

\begin{equation}
\begin{aligned}
W^{\text{cycle}}_{\infty\text{-step}} {} & = W^{\text{expansion}}_{\text{max}}+W^{\text{compression}}_{\text{min}} \\
 & = -nRT \ln \frac{V_f}{V_i}-nRT \ln \frac{V_i}{V_f} \\
 & = -nRT \underbrace{\left( \ln \frac{V_f}{V_i} - \ln \frac{V_f}{V_i} \right) }_{=0}  = 0,
\end{aligned}
  \label{eq:Wtot2}
\end{equation}

which means that, in this case, work is not destroyed nor created.

\begin{quote}
In practice, if we were able to perform this cycle manually by pushing on the piston down by hand, we will notice that it requires the same amount of energy to push down than the amount it gives back when it moves up.
\end{quote}

This process can happen both ways without losses, and is called \emph{reversible}:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:reversible}{}{\label{def:reversible} }\emph{Reversible process:} a process whose direction can be returned to its original position by inducing infinitesimal changes to some property of the system via its surroundings.\footnote{Definition from: Sears, F.W. and Salinger, G.L. (1986), Thermodynamics, Kinetic Theory, and Statistical Thermodynamics, 3rd edition (Addison-Wesley.)}
\end{definition}
\end{quote}

Reversible processes are ideal processes that are hard to realize in practice since they require transformations that happen in an infinite amount of steps (infinitely slowly).

\newcommand*{\standardstate}{{-\kern-6pt{\ominus}\kern-6pt-}}

\hypertarget{Thermochemistry}{%
\chapter{Thermochemistry}\label{Thermochemistry}}

\hypertarget{rxnenthalpy}{%
\section{Reaction Enthalpies}\label{rxnenthalpy}}

In the previous chapter, we have discussed thermodynamical changes in energy in the absence of chemical reactions. When a chemical reaction takes place, some bonds break and/or some new one form. This process either absorbs or releases the energy contained in these bonds. For a proper thermodynamic treatment of the system, this extra energy must be included in the net balance.

In this chapter, we will consider the heat associated with chemical reactions. Since most chemical reactions happen at constant atmospheric pressure (isobaric conditions) in the lab, we can use eq. \eqref{eq:dh2} to replace the inexact differential of the heat with the exact differential of the state function called enthalpy. The advantage of this transformation is that it allows us to study the heat associated with chemical reactions at constant pressure independently of their path. If we call the molecules at the beginning of the reaction ``reactants'' and the molecules at the end of the reaction ``products,'' the heat associated with the reaction (rxn) is defined as:

\begin{equation}
  \Delta_{\text{rxn}} H = H_{\text{products}}-H_{\text{reactants}} \; .
  \label{eq:DHrxn1}
\end{equation}

For example, if we take a simple reaction of the form:

\[ \mathrm{A} + \mathrm{B} \rightarrow \mathrm{C} + \mathrm{D}, \]

the heat at constant pressure is equal to the enthalpy of reaction, which is calculated as:

\begin{equation}
  Q_P = \Delta_{\text{rxn}} H = \underbrace{ \left (H_{\mathrm{C}}+H_{\mathrm{D}} \right) }_{\text{products}} - \underbrace{\left( H_{\mathrm{A}}+H_{\mathrm{B}}\right)}_{\text{reactants}}.
  \label{eq:DHrxn2}
\end{equation}

Using the chemistry sign convention, Definition \ref{def:chemistryconv}, reactions are classified in terms of the sign of their reaction enthalpies as follows:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:exoendo}{}{\label{def:exoendo} }

\begin{itemize}
\tightlist
\item
  \(\Delta_{\text{rxn}} H > 0 \Rightarrow\) \emph{Endothermic reaction} (heat is gained by the system).
\item
  \(\Delta_{\text{rxn}} H < 0 \Rightarrow\) \emph{Exothermic reaction} (heat is lost by the system).
\end{itemize}
\end{definition}
\end{quote}

If we expand the sample reaction to account for its stoichiometry:

\[ a\mathrm{A} + b\mathrm{B} \rightarrow c\mathrm{C} + d\mathrm{D}, \]

where \(a,b,c,d\) are the stoichiometric coefficients of species \(\mathrm{A,B,C,D}\). Eq. \eqref{eq:DHrxn2} can be rewritten as:

\begin{equation}
  Q_P = \Delta_{\text{rxn}} H = \underbrace{\left( cH_{\mathrm{C}}+dH_{\mathrm{D}} \right) }_{\text{products}} - \underbrace{ \left( aH_{\mathrm{A}}+bH_{\mathrm{B}} \right)}_{\text{reactants}},
  \label{eq:DHrxn3}
\end{equation}

while for the most general case we can write it:

\begin{equation}
  \Delta_{\text{rxn}} H = \sum_i \nu_i H_i,
  \label{eq:DHrxn4}
\end{equation}

where \(\nu_i\) is the stoichiometric coefficient of species \(i\) with its own sign. The signs of the stoichiometric are defined according to eq. \eqref{eq:DHrxn3} as:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:nui}{}{\label{def:nui} }\emph{Signs of the stoichiometric coefficients:}

\begin{itemize}
\tightlist
\item
  \(\nu_i\) is \textbf{positive} if \(i\) is a \textbf{product}.
\item
  \(\nu_i\) is \textbf{negative} if \(i\) is a \textbf{reactant}.
\end{itemize}
\end{definition}
\end{quote}

\hypertarget{formenthalpy}{%
\section{Standard Enthalpies of Formation}\label{formenthalpy}}

In principle, we could use eq. \eqref{eq:DHrxn3} to calculate the reaction enthalpy associated with any reaction. However, to do so, the absolute enthalpies \(H_i\) of reactants and products would be required. Unfortunately, absolute enthalpies are not known---and theoretically unknowable, since this would require an absolute zero for the enthalpy scale, which does not exist.\footnote{An example of a known absolute zero for a scale is the zero of the temperature scale, a temperature that can be approached only as a limit from above. No such thing exists for the enthalpy.} To prevent this problem, enthalpies relative to a deﬁned reference state must be used. This reference state is defined at the constituent elements in their standard state, and the enthalpies of 1 mol of substance in this reference state are called \textbf{standard enthalpies of formation}.

\begin{quote}
\begin{definition}
\protect\hypertarget{def:stdenthapies}{}{\label{def:stdenthapies} }
The \emph{standard enthalpy of formation} of compound \(i\), \(\Delta_{\mathrm{f}} H_i^{-\kern-6pt{\ominus}\kern-6pt-}\), is the change of enthalpy during the formation of 1 mol of \(i\) from its constituent elements, with all substances in their standard states.
\end{definition}
\end{quote}

The standard pressure is defined at \(P^{{-\kern-6pt{\ominus}\kern-6pt-}} = 100 \; \mathrm{kPa} = 1 \; \mathrm{bar}\).\footnote{prior to 1982 the value of \(P^{{-\kern-6pt{\ominus}\kern-6pt-}} = 1.0 \mathrm{ atm}\) was used. The two values of \(P^{-\kern-6pt{\ominus}\kern-6pt-}\) are within 1\% of each other, since 1 atm = 101.325 kPa.} There is no standard temperature, but standard enthalpies of formation are usually reported at room temperature, \(T = 298.15 \; \mathrm{K}\). Standard states are indicated with the symbol \({-\kern-6pt{\ominus}\kern-6pt-}\) and they are defined for elements as the form in which such element is most stable at standard pressure (for example, for hydrogen, carbon, and oxygen the standard states are \(\mathrm{H}_{2(g)}, \mathrm{C}_{(s,\text{graphite})}, \text{and }\mathrm{O}_{2(g)}\), respectively).\footnote{There are some exception, such as phosphorus, for which the most stable form at 1 bar is black phosphorus, but white phosphorus is chosen as the standard reference state for zero enthalpy of formation. For the purposes of this course, however, we can safely ignore them.}

For example, the standard enthalpies of formation of some common compounds at \(T = 298.15 \; \mathrm{K}\) are calculated from the following reactions:

\begin{equation}
\begin{aligned}
  \mathrm{C}_{(s,\text{graphite})}+\mathrm{O}_{2(g)} \rightarrow \mathrm{CO}_{2(g)} \qquad & \Delta_{\mathrm{f}} H_{\mathrm{CO}_{2(g)}}^{-\kern-6pt{\ominus}\kern-6pt-}= -394 \; \text{kJ/mol} \\
   \mathrm{C}_{(s,\text{graphite})}+2 \mathrm{H}_{2(g)} \rightarrow \mathrm{CH}_{4(g)} \qquad & \Delta_{\mathrm{f}} H_{\mathrm{CH}_{4(g)}}^{-\kern-6pt{\ominus}\kern-6pt-}= -75 \; \text{kJ/mol} \\ 
   \mathrm{H}_{2(g)}+\frac{1}{2} \mathrm{O}_{2(g)} \rightarrow \mathrm{H}_2 \mathrm{O}_{(l)} \qquad & \Delta_{\mathrm{f}} H_{\mathrm{H}_2 \mathrm{O}_{(g)}}^{-\kern-6pt{\ominus}\kern-6pt-}= -286 \; \text{kJ/mol} 
\end{aligned}
\label{eq:someDfH}
\end{equation}

\hypertarget{hessslaw}{%
\section{Hess's Law}\label{hessslaw}}

The calculation of a standard reaction enthalpy can be performed using the following cycle:

\begin{equation}
\begin{aligned}
 \text{reactants} & \quad \xrightarrow{\Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}} \quad \text{products} \\
\scriptstyle{-\Delta_{\text{f}} H_{\text{reactants}}^{-\kern-6pt{\ominus}\kern-6pt-}} \quad \bigg\downarrow \quad & \qquad \qquad \qquad \qquad \scriptstyle{\bigg\uparrow  \; \Delta_{\text{f}} H_{\text{products}}^{-\kern-6pt{\ominus}\kern-6pt-}} \\
 \text{"elements in } & \text{their standard reference state"}
\end{aligned}
\label{eq:Hesscycle}
\end{equation}

This process is summarized by the simple formula:

\begin{equation}
  \Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}= \Delta_{\mathrm{f}} H_{\text{products}}^{-\kern-6pt{\ominus}\kern-6pt-}- \Delta_{\mathrm{f}} H_{\text{reactants}}^{-\kern-6pt{\ominus}\kern-6pt-}.
  \label{eq:Hess1}
\end{equation}

Notice how there is a negative sign in front of the enthalpy of formation of the reactants because they are normally defined for the reactions that go from the elements to the reactants and not vice-versa. To close the cycle in eq. \eqref{eq:Hesscycle}, however, we should go from the reactants to the elements, and therefore we must invert the sign in front of the formation enthalpies of the reactants. Eq. \eqref{eq:Hess1} can be generalized using the same technique used to derive eq. \eqref{eq:DHrxn4}, resulting in:

\begin{equation}
  \Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}= \sum_i \nu_i \Delta_{\mathrm{f}} H_i^{-\kern-6pt{\ominus}\kern-6pt-},
  \label{eq:Hess}
\end{equation}

which is a mathematical expression of the law that is known as \textbf{Hess's Law}. Hess's law is valid at constant pressure because, at those conditions, the heat of reaction---a path function---is equal to the enthalpy of reaction---a state function. Therefore, the enthalpy of a reaction depends exclusively on the initial and final state, and it can be obtained via the pathway that passes through the elements in their standard state (the formation pathway).

\begin{quote}
\begin{exercise}
\protect\hypertarget{exr:HessLawEx}{}{\label{exr:HessLawEx} }Calculate the standard enthalpy of formation at 298 K for the combustion of 1 mol of methane, using the data in eq. \eqref{eq:someDfH}.

\emph{Solution:} The reaction that is under consideration is:
\begin{equation}
  \mathrm{CH}_{4(g)} + 2 \mathrm{O}_{2(g)} \rightarrow \mathrm{CO}_{2(g)} + 2 \mathrm{H}_2 \mathrm{O}_{(l)} \qquad \Delta_{\mathrm{f}} H_{\mathrm{CH}_{4(g)}}^{-\kern-6pt{\ominus}\kern-6pt-}= ?
\end{equation}

Using Hess's Law, \eqref{eq:Hess}, the enthalpy of formation for methane is:

\begin{equation}
 \Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}=  \Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{CO}_{2(g)}} + 2 \Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_{2}O_{(l)}} - \Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{CH}_{4(g)}} - 2 \underbrace{\Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{O}_{2(g)}}}_{=0}
\end{equation}

whose values are reported in eqs. \eqref{eq:someDfH}. Notice that the formation enthalpy of \(O_{2(g)}\) is zero, since it is an element in its standard state. The final result is:

\begin{equation}
 \Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}=  \overbrace{-394}^{\Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{CO}_{2(g)}}} +2 \overbrace{(-286)}^{\Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_{2}O_{(l)}}} - \overbrace{(-75)}^{\Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{CH}_{4(g)}}}  = -891 \mathrm{kJ/mol}.
\end{equation}

where the negative sign indicates that the reaction is exothermic (see \ref{def:exoendo}), as we should expect. The cycle that we used to solve this exercise can be summarized with :

\begin{equation}
\begin{aligned}
\mathrm{CH}_{4(g)} + & 2 \mathrm{O}_{2(g)} \quad \xrightarrow{\Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}} \quad \mathrm{CO}_{2(g)} + 2 \mathrm{H}_2 \mathrm{O}_{(l)} \\
  \scriptstyle{-\Delta_{\text{f}} H_{\mathrm{CH}_{4(g)},\mathrm{O}_{2(g)}}^{-\kern-6pt{\ominus}\kern-6pt-}} & \searrow \qquad \qquad \qquad \qquad \qquad \nearrow \; \scriptstyle{\Delta_{\text{f}} H_{\text{CO}_{2(g)},\mathrm{H}_{2(g)}}^{-\kern-6pt{\ominus}\kern-6pt-}}\\
  & \qquad \mathrm{H}_{2(g)}, \mathrm{C}_{s,\text{graphite}}, \mathrm{O}_{2(g)}
\end{aligned}
\end{equation}

Notice that at standard pressure and \(T = 298 \; \mathrm{K}\) water is in liquid form. However, when we burn methane, the heat associated with the exothermic reaction immediately vaporize the water. Substances in different states of matter have different formation enthalpies, and \(\Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_{2}O_{(l)}} = -242 \  \mathrm{kJ/mol}\). The difference between the formation enthalpies of the same substance in different states represents the latent heat that separates them. For example, for water:

\begin{equation}
\begin{aligned}
\Delta_{\text{vap}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_2O} & = \Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_{2}O_{(g)}} - \Delta_{\text{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_{2}O_{(l)}} \\
& = (-242) - (-286) = + 44 \; \text{kJ/mol}
\end{aligned}
\end{equation}

which is the latent heat of vaporization for water, \(\Delta_{\text{vap}} H^{-\kern-6pt{\ominus}\kern-6pt-}_{\mathrm{H}_2O}\). The latent heat is positive to indicate that the system absorbs energy in going from the liquid to the gaseous state (and it will release energy when going the opposite direction from gas to liquid).
\end{exercise}
\end{quote}

\hypertarget{calculations-of-enthalpies-of-reaction-at-t-neq-298-textk}{%
\section{\texorpdfstring{Calculations of Enthalpies of Reaction at \(T \neq 298 \; \text{K}\)}{Calculations of Enthalpies of Reaction at T \textbackslash neq 298 \textbackslash; \textbackslash text\{K\}}}\label{calculations-of-enthalpies-of-reaction-at-t-neq-298-textk}}

Standard enthalpies of formation are usually reported at room temperature (\(T\) = 298 K), but enthalpies of formation at any temperature \(T'\) can be calculated from the values at 298 K using eqs. \eqref{eq:Cpdef} and \eqref{eq:dh2}:

\begin{equation}
\begin{aligned}
dH = C_P dT \rightarrow & \int_{H_{T=298}^{-\kern-6pt{\ominus}\kern-6pt-}}^{H_{T'}} dH =  \int_{T=298}^{T'} C_P dT \\
            & H_{T'}^{-\kern-6pt{\ominus}\kern-6pt-}- H_{T=298}^{-\kern-6pt{\ominus}\kern-6pt-}= \int_{T=298}^{T'} C_P dT \\
            & H_{T'}^{-\kern-6pt{\ominus}\kern-6pt-}= H_{T=298}^{-\kern-6pt{\ominus}\kern-6pt-}+ \int_{T=298}^{T'} C_P dT,
\end{aligned}
  \label{eq:DrxnHneq298}
\end{equation}

which, in conjunction with Hess's Law (eq. \eqref{eq:Hess}), results in:

\begin{equation}
 \Delta_{\text{rxn}} H_{T'}^{-\kern-6pt{\ominus}\kern-6pt-}= \Delta_{\text{rxn}} H_{T=298}^{-\kern-6pt{\ominus}\kern-6pt-}+ \int_{T=298}^{T'} \Delta C_P dT,
  \label{eq:DrxnHneq298f}
\end{equation}

with \(\Delta C_P = \sum_i \nu_i C_{P,i}\).

\begin{quote}
\begin{exercise}
\protect\hypertarget{exr:DHtdiff298}{}{\label{exr:DHtdiff298} }Calculate \(\Delta_{\text{rxn}}H\) of the following reaction at 398 K, knowing that \(\Delta_{\text{rxn}}H^{-\kern-6pt{\ominus}\kern-6pt-}\) at 298 K is -283.0 kJ/mol, and the following \(C_P\) values: \(\mathrm{CO}_{(g)}\) = 29 J/(mol K), \(\mathrm{O}_{2(g)}\) = 30 J/(mol K), \(\mathrm{CO}_{2(g)}\) = 38 J/(mol K):

\[
\mathrm{CO}_{(g)}+\frac{1}{2}\mathrm{O}_{2(g)} \rightarrow \mathrm{CO}_{2(g)},
\]

\emph{Solution:} Using eq. \eqref{eq:DrxnHneq298f} we obtain:

\[
 \Delta_{\text{rxn}} H_{398} = \overbrace{-283.0}^{\Delta_{\text{rxn}}^{-\kern-6pt{\ominus}\kern-6pt-}} + \int_{298}^{398} \left( \overbrace{38}^{C_P^{\mathrm{CO}_2}} -\overbrace{29}^{C_P^{\mathrm{CO}}} -\frac{1}{2}\overbrace{30}^{C_P^{\mathrm{O}_2}} \right) \times 10^{-3} dT,
\]

which, assuming that the heat capacities does not depend on the temperature, becomes:

\[
 \Delta_{\text{rxn}} H_{398} = -283.0 + \left(38-29-\frac{1}{2}30 \right) \times 10^{-3} (398-298) = -283.6 \; \text{kJ/mol}.
\]

As we notice from this result, a difference in temperature of 100 K translates into a change in \(\Delta_{\text{rxn}}H^{-\kern-6pt{\ominus}\kern-6pt-}\) of this reaction of only 0.6 kJ/mol. This is a trend that is often observed, and values of \(\Delta_{\text{rxn}}H\) are very weakly dependent on changes in temperature for most chemical reactions. This numerical result can also be compared with the amount that is experimentally measured for \(\Delta_{\text{rxn}}H^{398}\) of this reaction, which is -283.67 kJ/mol. This comparison strongly supports the assumption that we used to solve the integral in eq. \eqref{eq:DrxnHneq298f}, confirming that the heat capacities are mostly independent of temperature.
\end{exercise}
\end{quote}

\hypertarget{ThermodynamicCycles}{%
\chapter{Thermodynamic Cycles}\label{ThermodynamicCycles}}

The first law of thermodynamics places no restrictions on the conversion of energy from one form to another. For example, let's consider once again the Joule experiment (Figure \ref{fig:FigJexp}). If we design a cycle that goes from the gas on the left chamber only to the gas equilibrized in both chambers and backwards, as in Figure \ref{fig:FigJexpC}, there is no restrictions imposed on this hypothetical cycle by the first law.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.008} 

}

\caption{Closing the Cycle in The Joule Expansion Experiment}\label{fig:FigJexpC}
\end{figure}

As we saw in Section \ref{isothermalE}, states 1 and 2 have exactly the same energy at constant temperature. Restricting the analysis to the information contained in the first law, the ideal gas could hypothetically go from state 1 (all gas in the left chamber) to state 2 (gas in both chambers), as well as spontaneously close the cycle back from state 2 to state 1, without external intervention. While the transformation from 1 \(\rightarrow\) 2 is intuitively spontaneous (it's the same transformation that we considered in Section \ref{isothermalE}), the backward transformation from 2 \(\rightarrow\) 1 is clearly not as intuitive. In this case, the gas should spontaneously compress back to the left side, leaving vacuum on the right chambers, without us intervening from the outside. This transformation is clearly never observed. A gas just does not spontaneously concentrate on one side of a room, leaving a vacuum on the other side. In fact, when we need to create a vacuum, a lot of energy must be spent. If we look at the information contained in the first law, however, there is nothing that might suggest a preference for a system to perform the transformation 1 \(\rightarrow\) 2, while restricting the 2 \(\rightarrow\) 1 from happening spontaneously. Both states have the same energy, and

\begin{equation}
  \oint dU=0,
  \label{eq:de0c}
\end{equation}

James Joule himself was indeed convinced that this must be the case and that we don't observe the backward transformation in practice only because we cannot to build ideal machines.\footnote{Either because we don't really have ideal gases, or because we are unable to construct mechanical devices without loss, or in general because of other experimental factors} Another scientist of that era was not convinced. William Thomson, the 1\textsuperscript{st} Baron Kelvin (1824--1907), was unsure about this idea, and invested substantial resources to try to prove Joule's wrong.\footnote{Interestingly enough, both Joule and Lord Kelvin are now recognized as key figures in the development of thermodynamics and science in general. So much so, that the energy unit and the temperature unit in the SI system are named after them.}

A few years later, the controversy between Joule and Kelvin was redeemed in favor of the latter, thanks to the experiments of French military engineer Nicolas Léonard Sadi Carnot (1796--1832). The work of Carnot began in France several years before Joule and Kelvin's time.\footnote{Carnot's lone book, the \href{https://en.wikipedia.org/wiki/Reflections_on_the_Motive_Power_of_Fire}{\emph{Réflexions sur la Puissance Motrice du Feu} (``Reflections on the Motive Power of Fire'')} was published in France in 1824, the same year Kelvin was born and just 6 years after Joule's birth.} At that time, the importance of steam engines was growing for industrial applications, but a theoretical perspective was lacking. Carnot was convinced that a scientific understanding of heat engines was necessary to improve their efficiency.

\hypertarget{carnotcyclesect}{%
\section{Carnot Cycle}\label{carnotcyclesect}}

The main contribution of Carnot to thermodynamics is his abstraction of the steam engine's essential features into a more general and idealized heat engine. The definition of Carnot's idealized cycle is as follows:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:carnotcycle}{}{\label{def:carnotcycle} }
A \emph{Carnot cycle} is an idealized process that is composed of two isothermal and two adiabatic transformations. Each transformation is either an expansion or a compression of an \emph{ideal gas}. All transformations are assumed to be \emph{reversible} and no energy is lost to mechanical friction.
\end{definition}
\end{quote}

A Carnot cycle connects two ``heat reservoirs'' at temperatures \(T_h\) (hot) and \(T_l\) (low), respectively. The reservoirs have a large thermal capacity, so that their temperatures are unaffected by the cycle. The system is composed exclusively by the ideal gas, which is the only substance that changes temperature throughout the cycle. If we report the four transformation of a Carnot cycle on a \(PV\) diagram, we obtain the following plot:

\begin{figure}

{\centering \includegraphics{pchem1_files/figure-latex/FigCarnotPV-1} 

}

\caption{PV-Diagram of Carnot Cycle}\label{fig:FigCarnotPV}
\end{figure}

\hypertarget{CCstage1}{%
\subsection{\texorpdfstring{Stage 1: isothermal expansion \(A \rightarrow B\)}{Stage 1: isothermal expansion A \textbackslash rightarrow B}}\label{CCstage1}}

\begin{center}\includegraphics[width=0.7\linewidth]{./img/OEP_Figures.007a} \end{center}

Starting the analysis of the cycle from point \(A\) in Figure \ref{fig:FigCarnotPV},\footnote{The stages of a Carnot depicted at the beginning of each of this section and the following three ones are taken from \href{https://en.wikipedia.org/wiki/Carnot_cycle}{Wikipedia} and distributed under CC-BY-SA license.} the first transformation we encounter is an isothermal expansion at \(T_h\). Since the transformation is isothermal:

\begin{equation}
U_1 = \overbrace{W_1}^{<0} + \overbrace{Q_1}^{>0} = 0 \Rightarrow Q_1 = -W_1,
  \label{eq:CCst1}
\end{equation}

and heat and work can be calculated for this stage using either eqs. \eqref{eq:WintsolvedV} or \eqref{eq:WintsolvedP}:

\begin{equation}
\begin{aligned}
 Q_1 & = \left| Q_h \right|  = nRT_h \overbrace{\ln \frac{V_B}{V_A}}^{>0 \text{ since } V_B>V_A} > 0, \\
 W_1 & = -Q_1 = - nRT_h \ln \frac{V_B}{V_A} < 0,
\end{aligned}
  \label{eq:CCst1b}
\end{equation}

where we denote \(\left| Q_h \right|\) the absolute value of the heat that gets \textbf{into} the system from the hot reservoir.

\hypertarget{CCstage2}{%
\subsection{\texorpdfstring{Stage 2: adiabatic expansion \(B \rightarrow C\)}{Stage 2: adiabatic expansion B \textbackslash rightarrow C}}\label{CCstage2}}

\begin{center}\includegraphics[width=0.7\linewidth]{./img/OEP_Figures.007b} \end{center}

The second transformation is an adiabatic expansion between \(T_h\) and \(T_l\). Since we are at adiabatic conditions:

\begin{equation}
Q_2 = 0 \Rightarrow U_2 = W_2,
  \label{eq:CCst2}
\end{equation}

and the negative energy (expansion work) can be calculated using:

\begin{equation}
U_2 = W_2 = n \underbrace{\int_{T_h}^{T_l} C_V dT}_{<0 \text{ since } T_\mathrm{l}<T_\mathrm{h}} < 0.
  \label{eq:CCst2b}
\end{equation}

\hypertarget{CCstage3}{%
\subsection{\texorpdfstring{Stage 3: isothermal compression \(C \rightarrow D\)}{Stage 3: isothermal compression C \textbackslash rightarrow D}}\label{CCstage3}}

\begin{center}\includegraphics[width=0.7\linewidth]{./img/OEP_Figures.007c} \end{center}

The third transformation is an isothermal compression at \(T_l\). The formulas are the same as those used for stage 1, but they will results in heat and work with reversed signs (since this is a compression):

\begin{equation}
U_3 = \overbrace{W_3}^{>0} + \overbrace{Q_3}^{<0} = 0 \Rightarrow Q_3 = -W_3,
  \label{eq:CCst3}
\end{equation}

and:

\begin{equation}
\begin{aligned}
 Q_3 & = \left| Q_l \right|  = nRT_l \overbrace{\ln \frac{V_D}{V_C}}^{<0 \text{ since } V_D<V_C} < 0 , \\
 W_3 & = -Q_3 = - nRT_l \ln \frac{V_D}{V_C} > 0,
\end{aligned}
  \label{eq:CCst3b}
\end{equation}

where \(\left| Q_l \right|\) is the absolute value of the heat that gets \textbf{out of} the system to the cold reservoir (\(\left| Q_l \right|\) being the heat entering the system).

\hypertarget{CCstage4}{%
\subsection{\texorpdfstring{Stage 4: adiabatic compression \(D \rightarrow A\)}{Stage 4: adiabatic compression D \textbackslash rightarrow A}}\label{CCstage4}}

\begin{center}\includegraphics[width=0.7\linewidth]{./img/OEP_Figures.007d} \end{center}

The fourth and final transformation is an adiabatic comprssion that restores the system to point \(A\), bringing it from \(T_l\) to \(T_h\). Similarly to stage 3:

\begin{equation}
Q_4 = 0 \Rightarrow U_4 = W_4,
  \label{eq:CCst4}
\end{equation}

Since we are at adiabatic conditions. The energy associated with this process is now positive (compression work), and can be calculated using:

\begin{equation}
U_4 = W_4 = n \underbrace{\int_{T_l}^{T_h} C_V dT}_{>0 \text{ since } T_\mathrm{h}>T_\mathrm{l}} > 0.
  \label{eq:CCst4b}
\end{equation}

Notice how \(U_4 = -U_2\) because \(\int_x^y=-\int_y^x\).

\hypertarget{UWQCarnot}{%
\section{Energy, Heat, and Work in the Carnot Cycle}\label{UWQCarnot}}

Summarizing the results of the previous sections, the total amount of energy for a Carnot cycle is:

\begin{equation}
\begin{aligned}
  U_{\text{TOT}} & = U_1+U_2+U_3+U_4 \\
                 & = 0 + n \int_{T_h}^{T_l} C_V dT + 0 + n \int_{T_l}^{T_h} C_V dT  \\
                 & = n \int_{T_h}^{T_l} C_V dT - n \int_{T_h}^{T_l} C_V dT = 0 \\
\end{aligned}
  \label{eq:UtotCC}
\end{equation}

which is obviously zero, since \(\oint dU=0\). The amounts of work and heat, however, are not zero, since \(Q\) and \(W\) are path functions. Therefore:

\begin{equation}
\begin{aligned}
  W_{\text{TOT}} & = W_1+W_2+W_3+W_4 \\
                 & = - nRT_h \ln \frac{V_B}{V_A} + n \int_{T_h}^{T_l} C_V dT - nRT_l \ln \frac{V_D}{V_C} + n \int_{T_l}^{T_h} C_V dT \\
                 & = nRT_h \ln \frac{V_B}{V_A} + nRT_l \ln \frac{V_D}{V_C}, \\
\end{aligned}
  \label{eq:WtotCC}
\end{equation}

which, considering that \(V_C/V_D=V_B/V_A\), reduces to:

\begin{equation}
  W_{\text{TOT}} = - nR \left( T_h-T_l \right) \ln \frac{V_B}{V_A} < 0,
  \label{eq:WtotCC2}
\end{equation}

which is negative, because \(T_h>T_l\) and \(V_B>V_A\). Negative work means that the work is done by the system. In other words, the system is performing \(PV\)-work by transferring heat from a hot reservoir to a cold one via a Carnot cycle. On the other hand, for the heat:

\begin{equation}
\begin{aligned}
  Q_{\text{TOT}} & = Q_1+Q_2+Q_3+Q_4 \\
                 & = Q_h + 0 + Q_l + 0    \\
                 & = nRT_h \ln \frac{V_B}{V_A} + nRT_l \ln \frac{V_D}{V_C} \\
                 & = nR \left( T_h-T_l \right) \ln \frac{V_B}{V_A} = -W_{\text{TOT}},
\end{aligned}
  \label{eq:QtotCC}
\end{equation}

which, simplifies to:

\begin{equation}
W_{\text{TOT}}=-(Q_1+Q_3),
  \label{eq:WtotCC3}
\end{equation}

and, replacing \(Q_1\) and \(Q_3\) with the absolute values of the heats drawn from the hot and cold reservoirs, \(\left| Q_h \right|\), and \(\left| Q_l \right|\) respectively:

\begin{equation}
\left| W_{\text{TOT}} \right| = \left| Q_h \right| - \left| Q_l \right|,
  \label{eq:QtotCC2}
\end{equation}

or, in other words, more heat is extracted from the hot reservoir than it is put into the cold one. The difference between the absolute value of these amounts of heat gives the total work of the cycle. This process is depicted in Figure \ref{fig:FigCarnotEff}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.009} 

}

\caption{Carnot Cycle Diagram}\label{fig:FigCarnotEff}
\end{figure}

\begin{quote}
\begin{exercise}
\protect\hypertarget{exr:CarnotEx}{}{\label{exr:CarnotEx} }Up to this point, we have discussed Carnot cycles working in the hot \(rightarrow\) cold direction (\(A\) \(\rightarrow\) \(B\) \(\rightarrow\) \(C\) \(\rightarrow\) \(D\) \(\rightarrow\) \(A\)), since this is the primary mode of operation of heat engines that produce work. However, a heat engine could also---in principle---work in the reversed cold \(rightarrow\) hot direction (\(A\) \(\rightarrow\) \(D\) \(\rightarrow\) \(C\) \(\rightarrow\) \(B\) \(\rightarrow\) \(A\)). Write the equations for heat, work, and energy of each stage of a Carnot cycle going the opposite direction than the one discussed in Sections \ref{carnotcyclesect} and \ref{UWQCarnot}.

\emph{Solution:} When the heat engine works in reverse order, the formulas remain the same, but all the signs in front of \(Q\), \(W\), and \(U\) will be reversed. In this case, the total work would get \textbf{into} the systems and heat would be transferred from the cold reservoir to the hot one. Figure \ref{fig:FigCarnotEff} would be modified as:
\end{exercise}
\end{quote}

\begin{flushright}\includegraphics[width=0.6\linewidth]{./img/OEP_Figures.010} \end{flushright}

This reversed mode of operation is the basic principle behind refrigerators and air conditioning.

```

\hypertarget{efficiency-of-a-carnot-cycle}{%
\section{Efficiency of a Carnot Cycle}\label{efficiency-of-a-carnot-cycle}}

The efficiency (\(\varepsilon\)) of a cycle is defined as the ratio between the absolute value of the work extracted from the cycle (\(\left| W_{\text{TOT}} \right|\)) and the heat that gets into the system (\(\left| Q_h \right|\)):

\begin{equation}
\varepsilon = \frac{\left| W_{\text{TOT}} \right|}{\left| Q_h \right|} =\frac{-W_{\text{TOT}}}{Q_1}
\label{eq:effCC1}
\end{equation}

where the minus sign in front of the work is necessary because the efficiency is defined as a positive number. Replacing eq. \eqref{eq:WtotCC3} into \eqref{eq:effCC1}, we obtain:

\begin{equation}
\varepsilon = \frac{Q_3+Q_1}{Q_1} = 1+\frac{Q_3}{Q_1}.
\label{eq:effCC2}
\end{equation}

If we go back to eq. \eqref{eq:effCC1} and we replace eq. \eqref{eq:WtotCC2} for \(W_{\mathrm{TOT}}\) and eq. \eqref{eq:CCst1b} for \(Q_1\), we obtain:

\begin{equation}
\varepsilon = \frac{nR \left( T_h - T_l \right) \ln V_B/V_A}{nRT_h \ln V_B/V_A} = \frac{T_h-T_l}{T_h}=1-\frac{T_l}{T_h }<1,
\label{eq:effCC3}
\end{equation}

which proves that the efficiency of a Carnot cycle is strictly smaller than 1.\footnote{Eq. \eqref{eq:effCC3} can be equal to 1 only if \(T_l=0 \; \text{K}\) or \(T_h=\infty\), two conditions that are both equally impossible.} In other words, no cycle can convert 100\% of the heat into work it extracts from a hot reservoir. This finding had remarkable consequences on the entire thermodynamics field and set the foundation for the introduction of entropy. We will use eqs. \eqref{eq:effCC1} and \eqref{eq:effCC3} for this purpose in the next chapter, but we conclude the discussion on Carnot cycles by returning back to Lord Kelvin. In 1851 he used this finding to state his statement ``It is impossible for a self-acting machine, unaided by any external agency, to convey heat from one body to another at a higher temperature. It is impossible, by means of inanimate material agency, to derive mechanical effect from any portion of matter by cooling it below the temperature of the coldest of the surrounding objects.''\footnote{Thomson W. \href{https://www.biodiversitylibrary.org/item/126047\#page/295/mode/1up}{Transactions of the Royal Society of Edinburgh. 1851 XX 261--268, 289--298.}.} This statement conclusively disproved Joule's original theories and demonstrated that there is some fundamental principle to govern the flow of heat beyond the first law of thermodynamics.

\hypertarget{SecondLaw}{%
\chapter{Second Law of Thermodynamics}\label{SecondLaw}}

In the previous Chapter, we have discussed heat engines as a mean of understanding how some processes are spontaneous while others are not. Carnot's findings did not just simply inspired Lord Kelvin on this subject, but they also motivated Rudolf Clausius (1822--1888) introducing the concept of entropy. In this Chapter, we will also discuss entropy in the context of the second and the third law of thermodynamics.

\hypertarget{entropyint}{%
\section{Entropy in Thermodynamics}\label{entropyint}}

Let's return to the definition of efficiency of a Carnot cycle and bring together eqs. \eqref{eq:effCC2} and \eqref{eq:effCC3}:

\begin{equation}
\varepsilon = 1+\frac{Q_3}{Q_1} = 1-\frac{T_l}{T_h}.
\label{eq:effcQT}
\end{equation}

Simplifying this equality, we obtain:

\begin{equation}
\frac{Q_3}{T_l} = -\frac{Q_1}{T_h},
\label{eq:effcQTrearr}
\end{equation}

or alternatively:

\begin{equation}
\frac{Q_3}{T_l} + \frac{Q_1}{T_h} = 0.
\label{eq:effcQTrearr2}
\end{equation}

The left hand side of eq. \eqref{eq:effcQTrearr2} contains the sum of two quantities around the Carnot cycle, each calculated as \(\frac{Q_{\mathrm{REV}}}{T}\), with \(Q_{\mathrm{REV}}\) being the heat exchanged at reversible conditions (recall that according to Definition \ref{def:carnotcycle} each transformation in a Carnot cycle is reversible). Eq. \eqref{eq:effcQTrearr} can be generalized to a sequence of connected Carnot cycles joining more than two isotherms by taking the summation across different temperatures:

\begin{center}\includegraphics{pchem1_files/figure-latex/unnamed-chunk-12-1} \end{center}

\begin{equation}
\sum_i \frac{Q_{\mathrm{REV}}}{T_i} = 0,
\label{eq:effQrevT}
\end{equation}

where the summation happens across a sequence of Carnot cycles that connects different temperatures. Eqs. \eqref{eq:effcQTrearr2} and \eqref{eq:effQrevT} show that for a Carnot cycle---or a series of connected Carnot cycles---there exists a conserved quantity obtained by dividing the heat associated with each reversible stage and the temperature at which such heat is exchanged. If a quantity is conserved around a cycle, it must be independent on the path, and therefore it is a state function. Looking at similar equations, Clausius introduced in 1865 a new state function in thermodynamics, which he decided to call entropy and indicate with the letter \(S\):

\begin{quote}
\begin{definition}
\protect\hypertarget{def:entropy}{}{\label{def:entropy} }\emph{Entropy:} \begin{equation}
S = \frac{Q_{\mathrm{REV}}}{T}.
\end{equation}
\end{definition}
\end{quote}

We can use the new state function to generalize eq. \eqref{eq:effQrevT} to any reversible cycle in a \(PV\)-diagram by using the rules of calculus. First, we will slice \(S\) into an infinitesimal quantity:

\begin{equation}
dS = \frac{đQ_{\mathrm{REV}}}{T},
\label{eq:dentropy}
\end{equation}

then we can extend the summation across temperatures of eq. \eqref{eq:effQrevT} to a sum over infinitesimal quantities---that is the integral---around the cycle:

\begin{equation}
\oint dS = \oint \frac{đQ_{\mathrm{REV}}}{T} = 0.
\label{eq:ds0}
\end{equation}

\hypertarget{irreversible-cycles}{%
\section{Irreversible Cycles}\label{irreversible-cycles}}

Up to this point, we have discussed \emph{reversible} cycles only. Notice that the heat that enters the definition of entropy (Definition \ref{def:entropy} is the heat exchanged at reversible conditions since it is only at those conditions that the right-hand side of eq. \eqref{eq:dentropy} becomes a state function. What happens when we face an irreversible cycle? The efficiency of a Carnot cycle in eq. \eqref{eq:effCC3} is the maximum efficiency that an idealized thermodynamic cycle can reach. As such, any irreversible cycle will incontrovertibly have an efficiency smaller than the maximum efficiency of the idealized Carnot cycle. Therefore, eq. \eqref{eq:effcQT} for an \emph{irreversible} cycle will not hold anymore, and must be rewritten as:

\begin{equation}
\overbrace{1+\frac{Q_3}{Q_1}}^{\varepsilon_{\mathrm{IRR}}} < \overbrace{1-\frac{T_l}{T_h}}^{\varepsilon_{\mathrm{REV}}},
\label{eq:effcIRR}
\end{equation}

and, following the same procedure used in Section \ref{entropyint}, we can rewrite eq. \eqref{eq:effcIRR} as:

\begin{equation}
\frac{Q_3}{Q_1} < - \frac{T_l}{T_h} \longrightarrow \frac{Q_3}{T_l} + \frac{Q_1}{T_h} < 0 \longrightarrow \sum_i \frac{Q}{T} < 0,
\label{eq:effcIRR2}
\end{equation}

which can be generalized using calculus to:

\begin{equation}
\oint \frac{đQ_{\mathrm{IRR}}}{T} < 0.
\label{eq:dqirrineq}
\end{equation}

Putting eqs. \eqref{eq:ds0} and \eqref{eq:dqirrineq} together, we obtain:

\begin{equation}
\oint \frac{đQ}{T} \leq 0,
\label{eq:clausiusineq}
\end{equation}

where the equal sign holds for reversible transformations exclusively, while the inequality sign holds for irreversible ones. Eq. \eqref{eq:clausiusineq} is known as \textbf{Clausius inequality}.

\hypertarget{secondlaw}{%
\section{The Second Law of Thermodynamics}\label{secondlaw}}

Now we can consider an isolated system undergoing a cycle composed of an irreversible forward transformation (1 \(\rightarrow\) 2) and a reversible backward transformation (2 \(\rightarrow\) 1), as in Figure \ref{fig:FigJexpC2}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./img/OEP_Figures.011} 

}

\caption{Spontaneous and Non-Spontaneous Transformations in a Cycle}\label{fig:FigJexpC2}
\end{figure}

This cycle is similar to the cycle depicted in Figure \ref{fig:FigJexpC} for the Joule's expansion experiment. In this case, we have an intuitive understanding of the spontaneity of the irreversible expansion process, while the non-spontaneity of the backward compression. Since the cycle has at least one step that is irreversible, it is overall irreversible, and we can calculate:

\begin{equation}
\oint \frac{đQ_{\mathrm{IRR}}}{T} = \int_1^2 \frac{đQ_{\mathrm{IRR}}}{T} + \int_2^1 \frac{đQ_{\mathrm{REV}}}{T}.
\label{eq:qirrcycle}
\end{equation}

We can then use Clausius inequality (eq. \eqref{eq:clausiusineq}) to write:

\begin{equation}
\begin{aligned}
\int_1^2 \frac{đQ_{\mathrm{IRR}}}{T} + \int_2^1 \frac{đQ_{\mathrm{REV}}}{T} < 0,
\end{aligned}
\label{eq:qirrcycle1}
\end{equation}

which can be rearranged as:

\begin{equation}
\underbrace{\int_1^2 \frac{đQ_{\mathrm{REV}}}{T}}_{\int_1^2 dS = \Delta S} > \underbrace{\int_1^2 \frac{đQ_{\mathrm{IRR}}}{T}}_{=0},
\label{eq:qirrcycle2}
\end{equation}

where we have used the fact that, for an isolated system (the universe), \(đQ_{\mathrm{IRR}}=0\). Eq. \eqref{eq:qirrcycle2} can be rewritten as:

\begin{equation}
\Delta S > 0,
\label{eq:secondlaweq}
\end{equation}

which proves that for any irreversible process in an isolated system, the entropy is increasing. Using eq. \eqref{eq:secondlaweq} and considering that the only system that is truly isolated is the universe, we can write a concise statement for a new fundamental law of thermodynamics:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:secondlawdef}{}{\label{def:secondlawdef} }\emph{Second Law of Thermodynamics:} for any spontaneous process, the entropy of the universe is increasing.
\end{definition}
\end{quote}

\renewcommand*{\standardstate}{{-\kern-6pt{\ominus}\kern-6pt-}}

\hypertarget{thirdlaw}{%
\chapter{Third Law of Thermodynamics}\label{thirdlaw}}

The Second Law can be used to infer the spontaneity of a process, as long as the entropy of the universe is considered. To do so, we need to remind ourselves that the universe can be divided into a system and its surroundings (environment). When we calculate the entropy of the universe as an indicator of the spontaneity of a process, we need to \emph{always} consider changes in entropy in \emph{both} the system (syst) and its surroundings (surr):

\begin{equation}
\Delta S^{\mathrm{universe}} = \Delta S^{\mathrm{sys}} + \Delta S^{\mathrm{surr}},
\label{eq:dsuniv}
\end{equation}

or, in differential form:

\begin{equation}
d S^{\mathrm{universe}} = d S^{\mathrm{sys}} + d S^{\mathrm{surr}},
\label{eq:dsunivd}
\end{equation}

\hypertarget{dssys}{%
\section{\texorpdfstring{Calculation of \(\Delta S^{\mathrm{sys}}\)}{Calculation of \textbackslash Delta S\^{}\{\textbackslash mathrm\{sys\}\}}}\label{dssys}}

In general \(\Delta S^{\mathrm{sys}}\) can be calculated using either its Definition \ref{def:entropy}, or its differential formula, eq. \eqref{eq:dentropy}. In practice, it is always convenient to keep in mind that entropy is a state function, and as such it does not depend on the path. For this reason, we can break every transformation into elementary steps, and calculate the entropy on any path that goes from the initial state to the final state, such as, for example:

\begin{equation}
\begin{aligned}
P_i, T_i & \quad \xrightarrow{ \Delta_{\text{TOT}} S_{\text{sys}} } \quad P_f, T_f \\
  \scriptstyle{\Delta_1 S^{\text{sys}}} & \searrow \qquad  \qquad \nearrow \; \scriptstyle{\Delta_2 S^{\text{sys}}} \\
& \qquad P_i, T_f \\
\\
\Delta_{\text{TOT}} S^{\text{sys}} & = \Delta_1 S^{\text{sys}} + \Delta_2 S^{\text{sys}},
\end{aligned}
\label{eq:entropycycle}
\end{equation}

with \(\Delta_1 S^{\text{sys}}\) calculated at constant \(P\), and \(\Delta_2 S^{\text{sys}}\) at constant \(T\). The most important elementary steps from which we can calculate the entropy resemble the prototypical processes for which we calculated the energy in Section \ref{energyint}.

\hypertarget{entropy-in-isothermal-processes}{%
\subsection{Entropy in isothermal processes}\label{entropy-in-isothermal-processes}}

\begin{itemize}
\item
  For an ideal gas at constant temperature \(\Delta U =0\), and \(Q_{\mathrm{REV}} = -W_{\mathrm{REV}}\). Using the formula for \(W_{\mathrm{REV}}\) in either eq. \eqref{eq:WintsolvedV} or eq. \eqref{eq:WintsolvedP}, we obtain:
  \begin{equation}
  \Delta S^{\mathrm{sys}} = \int_i^f \frac{đQ_{\mathrm{REV}}}{T} = \frac{-W_{\mathrm{REV}}}{T} = \frac{nRT \ln \frac{V_f}{V_i}}{T} = nR \ln \frac{V_f}{V_i},
  \label{eq:sigconsttV}
  \end{equation}
  or, similarly:
  \begin{equation}
  \Delta S^{\mathrm{sys}} = nR \ln \frac{P_i}{P_f}.
  \label{eq:sigconsttP}
  \end{equation}
\item
  A phase change is a particular case of an isothermal process that does not follow the formulas introduced above, since an ideal gas never liquefies. The entropy associated with a phase change at constant pressure, however, can be calculated from its definition, remembering that \(Q_{\mathrm{rev}}= \Delta H\). For example for vaporizations:
\end{itemize}

\begin{equation}
\Delta_{\mathrm{vap}} S = \frac{\Delta_{\mathrm{vap}}H}{T_B},
\label{eq:spc}
\end{equation}

with \(\Delta_{\mathrm{vap}}H\) being the enthalpy of vaporization of a substance, and \(T_B\) its boiling temperature.

It is experimentally observed that the entropies of vaporization of many liquids have almost the same value of:

\begin{equation}
\Delta_{\mathrm{vap}} S \approx 10.5 R,
\label{eq:trouton}
\end{equation}

which corresponds in SI to the range of about 85--88 J/(mol K). This simple rule is named \textbf{Trouton's rule}, after the French scientist that discovered it, Frederick Thomas Trouton (1863-1922).

\begin{quote}
\begin{exercise}
\protect\hypertarget{exr:troutonex}{}{\label{exr:troutonex} }Calculate the standard entropy of vaporization of water knowing \(\Delta_{\mathrm{vap}} H_{\mathrm{H}_2\mathrm{O}}^{-\kern-6pt{\ominus}\kern-6pt-}= 44 \  \text{kJ/mol}\), as calculated in Exercise \ref{exr:HessLawEx}.

\emph{Solution:} Using eq. \eqref{eq:trouton}---and knowing that at standard conditions of \(P^{-\kern-6pt{\ominus}\kern-6pt-}= 1 \  \text{bar}\) the boiling temperature of water is 373 K---we calculate:

\begin{equation}
\Delta_{\mathrm{vap}} S_{\mathrm{H}_2\mathrm{O}}^{-\kern-6pt{\ominus}\kern-6pt-}= \frac{44 \times 10^3 \text{J/mol}}{373 \ \text{K}} = 118 \  \text{J/(mol K)}.
\label{eq:trouton1}
\end{equation}

The entropy of vaporization of water is far from Trouton's rule range of 85--88 J/(mol K) because of the hydrogen bond interactions between its molecules. Other similar exceptions are ethanol, formic acid, and hydrogen fluoride.
\end{exercise}
\end{quote}

\hypertarget{entropy-in-adiabatic-processes}{%
\subsection{Entropy in adiabatic processes}\label{entropy-in-adiabatic-processes}}

Since adiabatic processes happen without the exchange of heat, \(đQ=0\), it would be tempting to think that \(\Delta S^{\mathrm{sys}} = 0\) for every one of them. A transformation at constant entropy (isentropic) is always, in fact, a reversible adiabatic process. However, the opposite case is not always true, and an irreversible adiabatic transformation is usually associated with a change in entropy. To explain this fact, we need to recall that the definition of entropy includes the heat exchanged at reversible conditions only. Therefore, for irreversible adiabatic processes \(\Delta S^{\mathrm{sys}} \neq 0\). The calculation of the entropy change for an irreversible adiabatic transformation requires a substantial effort, and we will not cover it at this stage. The situation for adiabatic processes can be summarized as follows:

\begin{equation}
\begin{aligned}
\text{reversible:} \qquad & \frac{đQ_{\mathrm{REV}}}{T} = 0 \longrightarrow \Delta S^{\mathrm{sys}} = 0 \quad \text{(isenthalpic),}\\
\text{irreversible:} \qquad & \frac{đQ_{\mathrm{IRR}}}{T}  = 0 \longrightarrow \Delta S^{\mathrm{sys}} \neq 0. \\
\end{aligned}
\label{eq:adiabaticent}
\end{equation}

\hypertarget{entropy-in-isochoric-processes}{%
\subsection{Entropy in isochoric processes}\label{entropy-in-isochoric-processes}}

We can calculate the heat exchanged in a process that happens at constant volume, \(Q_V\), using eq. \eqref{eq:Cvint1}. Since the heat exchanged at those conditions equals the energy (eq. \eqref{eq:dUqv}), and the energy is a state function, we can use \(Q_V\) regardless of the path (reversible or irreversible). The entropy associated with the process will then be:

\begin{equation}
\Delta S^{\mathrm{sys}} = \int_i^f \frac{đQ_{\mathrm{REV}}}{T} = \int_i^f nC_V \frac{dT}{T} dT,
\label{eq:sconstV1}
\end{equation}

which, assuming \(C_V\) independent of temperature and solving the integral on the right-hand side, becomes:

\begin{equation}
\Delta S^{\mathrm{sys}} \approx n C_V \ln \frac{T_f}{T_i}.
\label{eq:sconstV}
\end{equation}

\hypertarget{entropy-in-isobaric-processes}{%
\subsection{Entropy in isobaric processes}\label{entropy-in-isobaric-processes}}

Similarly to the constant volume case, we can calculate the heat exchanged in a process that happens at constant pressure, \(Q_P\), using eq. \eqref{eq:Cpdef}. Again, similarly to the previous case, \(Q_P\) equals a state function (the enthalpy), and we can use it regardless of the path to calculate the entropy as:

\begin{equation}
\Delta S^{\mathrm{sys}} = \int_i^f \frac{đQ_{\mathrm{REV}}}{T} = \int_i^f nC_P \frac{dT}{T},
\label{eq:sconstP1}
\end{equation}

which, assuming \(C_P\) independent of temperature and solving the integral on the right-hand side, becomes:

\begin{equation}
\Delta S^{\mathrm{sys}} \approx n C_P \ln \frac{T_f}{T_i}.
\label{eq:sconstP}
\end{equation}

\hypertarget{dssurr}{%
\section{\texorpdfstring{Calculation of \(\Delta S^{\mathrm{surr}}\)}{Calculation of \textbackslash Delta S\^{}\{\textbackslash mathrm\{surr\}\}}}\label{dssurr}}

While the entropy of the system can be broken down into simple cases and calculated using the formulas introduced above, the entropy of the surroundings does not require such a complicated treatment, and it can always be calculated as:

\begin{equation}
\Delta S^{\mathrm{surr}} = \frac{Q_{\text{surr}}}{T_{\text{surr}}}=\frac{-Q_{\text{sys}}}{T_{\text{surr}}},
\label{eq:dssurr}
\end{equation}

or, in differential form:

\begin{equation}
d S^{\mathrm{surr}} = \frac{đQ_{\text{surr}}}{T_{\text{surr}}}=\frac{-đQ_{\text{sys}}}{T_{\text{surr}}},
\label{eq:dssurrd}
\end{equation}

where the substitution \(Q_{\text{surr}}=-Q_{\text{sys}}\) can be performed regardless of whether the transformation is reversible or not. In other words, the surroundings always absorb heat reversibly. To justify this statement, we need to restrict the analysis of the interaction between the system and the surroundings to just the vicinity of the system itself. Outside of a generally restricted region, the rest of the universe is so vast that it remains untouched by anything happening inside the system.\footnote{Even if we think at the most energetic event that we could imagine happening here on earth---such as the explosion of an atomic bomb or the hit of a meteorite from outer space---such an event will not modify the average temperature of the universe by the slightest degree.} To facilitate our comprehension, we might consider a system composed of a beaker on a workbench. We can then consider the room that the beaker is in as the immediate surroundings. To all effects, the beaker+room combination behaves as a system isolated from the rest of the universe. The room is obviously much larger than the beaker itself, and therefore every energy production that happens in the system will have minimal effect on the parameters of the room. For example, an exothermal chemical reaction happening in the beaker will not affect the overall temperature of the room substantially. When we study our reaction, \(T_{\text{surr}}\) will be constant, and the transfer of heat from the reaction to the surroundings will happen at reversible conditions.

\begin{quote}
\begin{exercise}
\protect\hypertarget{exr:supercooledEx}{}{\label{exr:supercooledEx} }Calculate the changes in entropy of the universe for the process of 1 mol of supercooled water, freezing at --10°C, knowing the following data: \(\Delta_{\mathrm{fus}}H = 6 \; \text{kJ/mol}\), \(C_P^{\mathrm{H}_2 \mathrm{O}_{(l)}}=76 \; \text{J/(mol K)}\), \(C_P^{\mathrm{H}_2 \mathrm{O}_{(s)}}=38 \; \text{J/(mol K)}\), and assuming both \(C_P\) to be independent on temperature.

\emph{Solution:} \(\Delta S^{\mathrm{sys}}\) for the process under consideration can be calculated using the following cycle:

\begin{equation}
\begin{aligned}
\mathrm{H}_2 \mathrm{O}_{(l)} & \quad \xrightarrow{\quad \Delta S_{\text{sys}} \quad} \quad \mathrm{H}_2 \mathrm{O}_{(s)} \qquad \quad T=263\;K\\
\scriptstyle{\Delta S_1} \; \bigg\downarrow \quad & \qquad \qquad \qquad \qquad \scriptstyle{\bigg\uparrow  \; \Delta S_3} \\
\mathrm{H}_2 \mathrm{O}_{(l)} & \quad \xrightarrow{\quad \Delta S_2 \qquad} \quad \mathrm{H}_2\mathrm{O}_{(s)} \qquad T=273\;K\\
\\
\Delta S^{\text{sys}} & = \Delta S_1 + \Delta S_2 + \Delta S_3
\end{aligned}
\label{eq:supercooledsyst}
\end{equation}

\(\Delta S_1\) and \(\Delta S_3\) are the isochoric heating and cooling processes of liquid and solid water, respectively, and can be calculated filling the given data into eq. \eqref{eq:sconstP1}. \(\Delta S_2\) is a phase change (isothermal process) and can be calculated translating eq. \eqref{eq:spc} to the freezing transformation. Overall:

\begin{equation}
\begin{aligned}
\Delta S^{\text{sys}} & = \int_{263}^{273} \frac{C_P^{\mathrm{H}_2 \mathrm{O}_{(l)}}}{T}dT+\frac{-\Delta_{\mathrm{fus}}H}{273}+\int_{273}^{263} \frac{C_P^{\mathrm{H}_2 \mathrm{O}_{(s)}}}{T}dT \\
& = 76 \ln \frac{273}{263} - \frac{6 \times 10^3}{273} + 38 \ln \frac{263}{273}= -20.6 \; \text{J/K}.
\end{aligned}
\label{eq:supercooledsyst2}
\end{equation}

Don't be confused by the fact that \(\Delta S^{\text{sys}}\) is negative. This is \textbf{\emph{not}} the entropy of the universe, hence it tells \textbf{\emph{nothing}} about spontaneity! We can now calculate \(\Delta S^{\text{surr}}\) from \(Q_{\text{sys}}\), noting that we can calculate the enthalpy around the same cycle in eq. \eqref{eq:supercooledsyst}. To do that, we already have \(\Delta_{\mathrm{fus}}H\) from the given data, and we can calculate \(\Delta H_1\) and \(\Delta H_3\) using eq. \eqref{eq:Cpdef}.

\begin{equation}
\begin{aligned}
Q^{\text{sys}} & = \Delta H = \int_{263}^{273} C_P^{\mathrm{H}_2 \mathrm{O}_{(l)}} dT + (-\Delta_{\mathrm{fus}}H) + \int_{273}^{263} C_P^{\mathrm{H}_2 \mathrm{O}_{(s)}}dT \\
& = 76 \times 10^{-3} (273-263) - 6 + 38  \times 10^{-3} (263-273) = -5.6 \; \text{kJ/mol}. \\
\\
\Delta S^{\text{surr}} & = \frac{-Q_{\text{sys}}}{T}=\frac{5.6 \times 10^3}{263} = + 21.3 \; \text{J/K}. \\
\end{aligned}
\label{eq:supercooledsurr}
\end{equation}

Bringing \eqref{eq:supercooledsyst} and \eqref{eq:supercooledsurr} results together, we obtain:

\begin{equation}
\Delta S^{\text{universe}}=\Delta S^{\text{sys}} + \Delta S^{\text{surr}} =  -20.6+21.3=-0.7 \; \text{J/K}.
\label{eq:supercooledfinal}
\end{equation}

Since the entropy changes in the universe are positive, the process is spontaneous, as expected.
\end{exercise}
\end{quote}

\hypertarget{spontS}{%
\section{Clausius Theorem}\label{spontS}}

By replacing eq. \eqref{eq:dssurrd} into \eqref{eq:dsunivd} we can write the differential change in the entropy of the system as:

\begin{equation}
d S^{\mathrm{sys}} = d S^{\mathrm{universe}} - d S^{\mathrm{surr}} = d S^{\mathrm{universe}} + \frac{đQ_{\text{sys}}}{T}.
\label{eq:dssysd}
\end{equation}

According to the second law, for any spontaneous process \(d S^{\mathrm{universe}}\geq0\), and therefore, replacing it into eq. \eqref{eq:dssysd}:

\begin{equation}
d S^{\mathrm{sys}} \geq \frac{đQ}{T_{\text{surr}}},
\label{eq:dssyscrit7}
\end{equation}

which is the mathematical expression of the so-called \textbf{Clausius theorem}. Eq. \eqref{eq:dssyscrit7} distinguishes between three conditions:

\begin{equation}
\begin{aligned}
d S^{\mathrm{sys}} > \frac{đQ}{T} \qquad &\text{spontaneous, irreversible transformation} \\
d S^{\mathrm{sys}} = \frac{đQ}{T} \qquad &\text{reversible transformation} \\
d S^{\mathrm{sys}} < \frac{đQ}{T} \qquad &\text{non-spontaneous, irreversible transformation}, 
\end{aligned}
\label{eq:dssyscond}
\end{equation}

Clausius theorem provides a useful criterion to infer the spontaneity of a process, especially in cases where it's hard to calculate \(\Delta S^{\mathrm{universe}}\). Eq. \eqref{eq:dssyscrit7} requires knowledge of quantities that are dependent on the system exclusively, such as the difference in entropy, the amount of heat that crosses the boundaries and the absolute temperature of the process. If a process produces more entropy than the amount of heat that crosses the boundaries divided by the absolute temperature, the process will be spontaneous. Vice versa, if the entropy produced is smaller than the amount of heat crossing the boundaries divided by the abosulte temperature, the process will be non-spontaneous. The equality holds for systems in equilibrium with their surroundings, or for reversible processes, since they happen through a series of equilibrium states. Measuring or calculating these quantities might not always be the simplest of calculations. We will return to the Clausius theorem in the next chapter when we seek more convenient indicators of spontaneity.

\hypertarget{thirdlawsect}{%
\section{The Third Law of Thermodynamics}\label{thirdlawsect}}

In Chapter \ref{Thermochemistry}, we have discussed how to calculate reaction enthalpies for any reaction, given the formation enthalpies of reactants and products. In this section, we will try to do the same for reaction entropies. In this case, however, our task is simplified by a fundamental law of thermodynamics, introduced by Walther Hermann Nernst (1864--1941) in 1906.\footnote{Walther Nernst was awarded the 1920 Nobel Prize in Chemistry for his work in thermochemistry.} The statement that was initially known as Nernst's Theorem is now officially recognized as the third fundamental law of thermodynamics, and it has the following definition:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:thirdlawdef}{}{\label{def:thirdlawdef} }\emph{Third Law of Thermodynamics:} The entropy of a perfectly ordered, pure, crystalline substance is zero at \(T=0 \; \text{K}\).
\end{definition}
\end{quote}

This law sets an unambiguous zero of the entropy scale, similar to what happens with absolute zero in the temperature scale. The absolute value of the entropy of every substance can then be calculated in reference to this unambiguous zero. As such, absolute entropies are always positive. This is in stark contrast to what happened for the enthalpy. An unambiguous zero of the enthalpy scale is lacking, and standard formation enthalpies (which might be negative) must be agreed upon to calculate relative differences.

In simpler terms, given a substance \(i\), we are not able to measure absolute values of its enthalpy \(H_i\) (and we must resort to known enthalpy differences, such as \(\Delta_{\mathrm{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}\) at standard pressure). At the same time, for entropy, we can measure \(S_i\) thanks to the third law, and we usually report them as \(S_i^{-\kern-6pt{\ominus}\kern-6pt-}\). Reaction entropies can be calculated from the tabulated standard entropies as differences between products and reactants, using:

\begin{equation}
\Delta_{\text{rxn}} S^{-\kern-6pt{\ominus}\kern-6pt-}= \sum_i \nu_i S_i^{-\kern-6pt{\ominus}\kern-6pt-},
\label{eq:thirdlaweq}
\end{equation}

with \(\nu_i\) being the usual stoichiometric coefficients with their signs given in Definition \ref{def:nui}.

The careful wording in the definition of the third law \ref{def:thirdlawdef} allows for the fact that some crystal might form with defects (i.e., not as a perfectly ordered crystal). In this case, a residual entropy will be present even at \(T=0 \; \text{K}\). However, this residual entropy can be removed, at least in theory, by forcing the substance into a perfectly ordered crystal.\footnote{a procedure that---in practice---might be extremely difficult to achieve.}

An interesting corollary to the third law states that it is impossible to find a procedure that reduces the temperature of a substance to \(T=0 \; \text{K}\) in a finite number of steps.

\hypertarget{Potentials}{%
\chapter{Thermodynamic Potentials}\label{Potentials}}

\hypertarget{fundeq}{%
\section{Fundamental Equation of Thermodynamics}\label{fundeq}}

Let's summarize some of the results from the first and second law of thermodynamics that we have seen so far. For reversible processes in closed systems:

\begin{equation}
\begin{aligned}
\text{From 1}^{\text{st}} \text{ Law:} \qquad \quad & dU = đQ_{\mathrm{REV}}-PdV \\
\text{From The Definition of Entropy:} \qquad \quad & dS = \frac{đQ_{\mathrm{REV}}}{T} \rightarrow đQ_{\mathrm{REV}} = TdS \\
\\
\Rightarrow \quad & dU = TdS - PdV.
\end{aligned}
\label{eq:dunv}
\end{equation}

Eq. \eqref{eq:dunv} is called \textbf{the fundamental equation of thermodynamics} since it combines the first and the second laws. Even though we started the derivation above by restricting to reversible transformations only, if we look carefully at eq. \eqref{eq:dunv}, we notice that it exclusively involves state functions. As such, it applies to both reversible and irreversible processes. The fundamental equation, however, remains constrained to closed systems. This fact restricts its utility for chemistry, since when a chemical reaction happens, the mass in the system will change, and the system is no longer closed.

At the end of the 19\textsuperscript{th} century, Josiah Willard Gibbs (1839--1903) proposed an important addition to the fundamental equation to account for chemical reactions. Gibbs was able to do so by introducing a new quantity that he called the \textbf{chemical potential}. The chemical potential is defined as the amount of energy absorbed or released due to a change of the particle number of a given chemical species. The chemical potential of species \(i\) is usually abbreviated as \(\mu_i\), and it enters the fundamental equation of thermodynamics as:

\begin{equation}
dU = TdS-PdV+\sum_i\mu_i dn_i,
\label{eq:dunv2}
\end{equation}

where \(dn_i\) is the differential change in the number of moles of substance \(i\), and the summation extends over all chemical species in the system.

According to the fundamental equation, the internal energy of a system is a function of the three variables entropy, \(S\), volume, \(V\), and the numbers of moles \(\{n_i\}\).\footnote{In the case of the numbers of moles we include them in curly brackets to indicate that there might be more than one, depending on how many species undergo chemical reactions.} Because of their importance in determining the internal energy, these three variables are crucial in thermodynamics. Under several circumstances, however, they might not be the most convenient variables to use.\footnote{For example, we don't always have a simple way to calculate or to measure the entropy}. To emphasize the important connections given by the fundamental equation, we can use the notation \(U(S,V,\{n_i\})\) and we can term \(S\), \(V\), and \(\{n_i\}\) \textbf{natural variables} of the energy.

\hypertarget{thermpot}{%
\section{Thermodynamic Potentials}\label{thermpot}}

Starting from the fundamental equation, we can define new thermodynamic state functions that are more convenient to use under certain specific conditions. The new functions are determined by using a mathematical procedure called the Legendre transform. A Legendre transform is a linear change in variables that brings from an initial mathematical function to a new function obtained by subtracting one or more products of its conjugate variables.

Taking the internal energy as defined in eq. \eqref{eq:dunv}, we can perform such procedure by subtracting products of the following conjugate variables: \(T, S, P, V\). This procedure aims to define new state functions that depend on more convenient natural variables. The new functions are called ``thermodynamic potential energies,'' or simply \textbf{thermodynamic potentials}.\footnote{Even if we introduced both concepts in the same chapter, it is important to never confuse the \emph{thermodynamic potentials}---which are potential energy functions---with the \emph{chemical potential}---which have been introduced by Gibbs to study heat in chemical reactions.} An example of this procedure is given by the definition of enthalpy that we have already seen in Section \ref{enthalpy}. If we take the internal energy and subtract the product of pressure and volume, we obtain a new state function called enthalpy, as we did in eq. \eqref{eq:enthalpydef}). Taking the differential of this definition, we obtain:

\begin{equation}
dH = dU -VdP -PdV,
\label{eq:dhdef1}
\end{equation}

and using the fundamental equation (eq. \eqref{eq:dunv2}) to replace \(dU\), we obtain:

\begin{equation}
\begin{aligned}
dH & = TdS -PdV +\sum_i\mu_i dn_i -VdP -PdV  \\
   & = TdS - VdP +\sum_i\mu_i dn_i.
\end{aligned}
\label{eq:dhdef2}
\end{equation}

which is the fundamental equation for enthalpy. The natural variables of the enthalpy are \(S\), \(P\), and \(\{n_i\}\). The Legendre transform has allowed us to go from \(U(S,V,\{n_i\})\) to \(H(S,P,\{n_i\})\) by replacing the dependence on the extensive variable, \(V\), with an intensive one, \(P\).

Following the same procedure, we can perform another Legendre transform to replace the entropy with a more convenient intensive variable such as the temperature. This can be done by defining a new function called the Helmholtz free energy, \(A\), as:

\begin{equation}
A = U -TS
\label{eq:dadef1}
\end{equation}

which, taking the differential and using the fundamental equation (eq. \eqref{eq:dunv2}) becomes:

\begin{equation}
\begin{aligned}
dA &= dU -SdT -TdS = TdS - PdV +\sum_i \mu_i dn_i -SdT -TdS  \\
   &= -SdT -PdV +\sum_i \mu_i dn_i.
\end{aligned}
\label{eq:dadef2}
\end{equation}

The Helmholtz free energy is named after Hermann Ludwig Ferdinand von Helmholtz (1821---1894), and its natural variables are temperature, volume, and the number of moles.

Finally, suppose we perform a Legendre transform on the internal energy to replace both the entropy and the volume with intensive variables. In that case, we can define a new function called the Gibbs free energy, \(G\), as:

\begin{equation}
G = U -TS -PV
\label{eq:dgdef1}
\end{equation}

which, taking again the differential and using eq. \eqref{eq:dunv2} becomes:

\begin{equation}
\begin{aligned}
dG &= dU -SdT -TdS -VdP -PdV \\
   &= TdS - PdV +\sum_i\mu_i dn_i -SdT -TdS -VdP -PdV \\
   &= VdP -SdT +\sum_i\mu_i dn_i.
\end{aligned}
\label{eq:dgdef2}
\end{equation}

The Gibbs free energy is named after Willard Gibbs himself, and its natural variables are temperature, pressure, and number of moles.

A summary of the four thermodynamic potentials is given in the following table.

\begin{longtable}[]{@{}cccc@{}}
\toprule
\textbf{Name} & \textbf{Symbol} & \textbf{Fundamental Equation} & \textbf{Natural Variables}\tabularnewline
\midrule
\endhead
\textbf{Energy} & \(U\) & \(dU=TdS-PdV+\sum_i\mu_i dn_i\) & \(S,V,\{n_i\}\)\tabularnewline
\textbf{Enthalpy} & \(H\) & \(dH=TdS+VdP+\sum_i\mu_i dn_i\) & \(S,P,\{n_i\}\)\tabularnewline
\textbf{Helmholtz Free Energy} & \(A\) & \(dA=-Sdt-PdV+\sum_i\mu_i dn_i\) & \(T,V,\{n_i\}\)\tabularnewline
\textbf{Gibbs Free Energy} & \(G\) & \(dG=VdP-SdT+\sum_i\mu_i dn_i\) & \(T,P,\{n_i\}\)\tabularnewline
\bottomrule
\end{longtable}

The thermodynamic potentials are the analog of the potential energy in classical mechanics. Since the potential energy is interpreted as the capacity to do work, the thermodynamic potentials assume the following interpretations:

\begin{itemize}
\tightlist
\item
  Internal energy (\(U\)) is the capacity to do work plus the capacity to release heat.
\item
  Enthalpy (\(H\)) is the capacity to do non-mechanical work plus the capacity to release heat.
\item
  Gibbs free energy (\(G\)) is the capacity to do non-mechanical work.
\item
  Helmholtz free energy (\(A\)) is the capacity to do mechanical plus non-mechanical work.
\end{itemize}

Where non-mechanical work is defined as any type of work that is not expansion or compression (\(PV\)-work). A typical example of non-mechanical work is electrical work.

\hypertarget{freeenergies}{%
\section{Free Energies}\label{freeenergies}}

The Legendre transform procedure translates all information contained in the original function to the new one. Therefore, \(H(S,P,\{n_i\})\), \(A(T,V,\{n_i\})\), and \(G(T,P,\{n_i\})\) all contain the same information that is in \(U(S,V,\{n_i\})\). However, the new functions depend on different natural variables, and they are useful at different conditions. For example, when we want to study chemical changes, we are interested in studying the term \(\sum_i\mu_i dn_i\) that appears in each thermodynamic potential. To do so, we need to isolate the chemical term by keeping all other natural variables constant. For example, changes in the chemical term will correspond to changes in the internal energy at constant \(S\) and constant \(V\):

\begin{equation}
dU(S,V,\{n_i\}) = \sum_i\mu_i dn_i \quad \text{if} \quad dS=dV=0.
\label{eq:duchem}
\end{equation}

Similarly:

\begin{equation}
\begin{aligned}
dH(S,P,\{n_i\}) = \sum_i\mu_i dn_i \quad \text{if} \quad dS=dP=0, \\
dA(T,V,\{n_i\}) = \sum_i\mu_i dn_i \quad \text{if} \quad dT=dV=0, \\
dG(T,P,\{n_i\}) = \sum_i\mu_i dn_i \quad \text{if} \quad dT=dP=0.
\end{aligned}
\label{eq:dhagchem}
\end{equation}

The latter two cases are particularly interesting since most of chemistry happens at either constant volume (for example, several industrial processes in chemical plants), or constant pressure (for example, most processes in a chemistry lab). Since \(dS=0\) is not a requirement for both free energies to describe chemical changes, we can apply either of them to study non-isenthalpic processes. If a process is not isenthalpic, it increases the entropy of the universe or decreases it. Therefore---according to the second law---it is either spontaneous or not. Using this concept in conjunction with Clausius theorem, we can devise new criteria for inferring the spontaneity of a process that depends exclusively on the free energies.

Recalling Clausius theorem:

\begin{equation}
d S^{\mathrm{sys}} \geq \frac{đQ}{T_{\text{surr}}} \quad \longrightarrow \quad TdS \geq đQ,
\label{eq:dssyscrit}
\end{equation}

we can consider the two cases: constant \(V\) (\(đQ_V=dU\), left), and constant \(P\) (\(đQ_P=dH\), right):

\begin{equation}
\begin{aligned}
\text{constant} & \; V:           & \qquad \qquad & \qquad \qquad &     \text{constant} & \; P: \\
\\
TdS & \geq dU           & &   &     TdS & \geq dH, \\
\\
TdS -dU & \geq 0         & &   &      TdS -dH & \geq 0, \\
\end{aligned}
\label{eq:dadgder1}
\end{equation}

we can then simplify the definition of free energies, eqs. \eqref{eq:dadef2} and \eqref{eq:dgdef2}:

\begin{equation}
\begin{aligned}
\text{constant} & \; T,V:           & \qquad & \qquad &     \text{constant} & \; T,P: \\
\\
d(A)_{T,V} &= dU -TdS     & &   &       d(G)_{T,P} &= dH - TdS, \\ 
\\
dU = d(A)_{T,V} &+TdS       & &   &       dH = d(G)_{T,P} &+TdS,
\end{aligned}
\label{eq:dadgder3}
\end{equation}

and by merging \(dU\) and \(dH\) from eqs. \eqref{eq:dadgder3} into Clausius theorem expressed using eqs. \eqref{eq:dadgder1}, we obtain:

\begin{equation}
\begin{aligned}
TdS -d(A)_{T,P} &- TdS \geq 0 & &  & TdS -d(G)_{T,P} &- TdS \geq 0, \\
\\
d(A)_{T,P} & \leq 0 & & & d(G)_{T,P} & \leq 0. \\
\end{aligned}
\label{eq:dadgcond}
\end{equation}

These equations represent the conditions on \(dA\) and \(dG\) for inferring the spontaneity of a process, and can be summarized as follows:

\begin{quote}
\begin{definition}
\protect\hypertarget{def:helmgibbsminimum}{}{\label{def:helmgibbsminimum} }

\begin{itemize}
\tightlist
\item
  During a spontaneous process at constant \emph{temperature} and \emph{volume}, the \emph{Helmholtz free energy} will decrease \((dA<0)\), until it reaches a stationary point at which the system will be at equilibrium \((dA=0)\).
\item
  During a spontaneous process at constant \emph{temperature} and \emph{pressure}, the \emph{Gibbs free energy} will decrease \((dG<0)\), until it reaches a stationary point at which the system will be at equilibrium \((dG=0)\).
\end{itemize}
\end{definition}
\end{quote}

\begin{figure}

{\centering \includegraphics{pchem1_files/figure-latex/agfig-1} 

}

\caption{Behavior of Helmholtz (red) and Gibbs (blue) Free Energies for Spontaneous Transformations at Constant T,V (left) and Constant T,P (right)}\label{fig:agfig}
\end{figure}

\hypertarget{maxwell}{%
\section{Maxwell Relations}\label{maxwell}}

Let's consider the fundamental equations for the thermodynamic potentials that we have derived in Section \ref{fundeq}:

\begin{equation}
\begin{aligned}
dU(S,V,\{n_i\}) &= \enspace T dS -P dV + \sum_i \mu_i dn_i \\
dH(S,P,\{n_i\}) &= \enspace T dS + V dP + \sum_i \mu_i dn_i \\
dA(T,V,\{n_i\}) &= -S dT -P dV + \sum_i \mu_i dn_i \\
dG(T,P,\{n_i\}) &= -S dT + V dP + \sum_i \mu_i dn_i
\end{aligned}
\label{eq:dhagchem1}
\end{equation}

From the knowledge of the natural variable of each potential, we could reconstruct these formulas by using the total differential formula:

\begin{equation}
\begin{aligned}
dU(S,V,\{n_i\}) &= \underbrace{\left(\frac{\partial U}{\partial S} \right)_{V,\{n_i\}}}_{T} dS + \underbrace{\left(\frac{\partial U}{\partial V} \right)_{S,\{n_i\}}}_{-P} dV + \sum_i \underbrace{\left(\frac{\partial U}{\partial n_i} \right)_{S,V,\{n_{j \neq i}\}}}_{\mu_i} dn_i \\
dH(S,P,\{n_i\}) &= \underbrace{\left(\frac{\partial H}{\partial S} \right)_{P,\{n_i\}}}_{T} dS + \underbrace{\left(\frac{\partial H}{\partial P} \right)_{S,\{n_i\}}}_{V} dP + \sum_i \underbrace{\left(\frac{\partial H}{\partial n_i} \right)_{S,P,\{n_{j \neq i}\}}}_{\mu_i} dn_i \\
dA(T,V,\{n_i\}) &= \underbrace{\left(\frac{\partial A}{\partial T} \right)_{V,\{n_i\}}}_{-S} dT + \underbrace{\left(\frac{\partial A}{\partial V} \right)_{T,\{n_i\}}}_{-P} dV + \sum_i \underbrace{\left(\frac{\partial A}{\partial n_i} \right)_{T,V,\{n_{j \neq i}\}}}_{\mu_i} dn_i \\
dG(T,P,\{n_i\}) &= \underbrace{\left(\frac{\partial G}{\partial T} \right)_{V,\{n_i\}}}_{-S} dT + \underbrace{\left(\frac{\partial G}{\partial P} \right)_{T,\{n_i\}}}_{V} dP + \sum_i \underbrace{\left(\frac{\partial G}{\partial n_i} \right)_{T,P,\{n_{j \neq i}\}}}_{\mu_i} dn_i
\end{aligned}
\label{eq:dhagchem2}
\end{equation}

we can derive the following new definitions:

\begin{equation}
\begin{aligned}
 T &= \;\;\, \left(\frac{\partial U}{\partial S} \right)_{V,\{n_i\}}  = \;\;\, \left(\frac{\partial H}{\partial S} \right)_{P,\{n_i\}}  \\
 P &= -\left(\frac{\partial U}{\partial V} \right)_{S,\{n_i\}} = -\left(\frac{\partial A}{\partial V} \right)_{T,\{n_i\}}  \\
 V &= \;\;\, \left(\frac{\partial H}{\partial P} \right)_{S,\{n_i\}}  = \;\;\, \left(\frac{\partial G}{\partial P} \right)_{T,\{n_i\}}  \\
 S &= -\left(\frac{\partial A}{\partial T} \right)_{V,\{n_i\}} = -\left(\frac{\partial G}{\partial T} \right)_{V,\{n_i\}}  \\
\text{and:}
\\
 \mu_i &=  \left(\frac{\partial U}{\partial n_i} \right)_{S,V,\{n_{j \neq i}\}} =  \left(\frac{\partial H}{\partial n_i} \right)_{S,P,\{n_{j \neq i}\}} \\
       &= \left(\frac{\partial A}{\partial n_i} \right)_{T,V,\{n_{j \neq i}\}} = \left(\frac{\partial G}{\partial n_i} \right)_{T,P,\{n_{j \neq i}\}}
\end{aligned}
\label{eq:dhagchem3}
\end{equation}

Since \(T\), \(P\), \(V\), and \(S\) are now defined as partial first derivatives of a thermodynamic potential, we can now take a second partial derivation with respect to a separate variable, and rely on Schwartz's theorem on c to derive the following relations:

\begin{equation}
\begin{aligned}
\frac{\partial^2 U }{\partial S \partial V} &=& +\left(\frac{\partial T}{\partial V}\right)_{S,\{n_{j \neq i}\}} &=& -\left(\frac{\partial P}{\partial S}\right)_{V,\{n_{j \neq i}\}}   \\
\frac{\partial^2 H }{\partial S \partial P} &=& +\left(\frac{\partial T}{\partial P}\right)_{S,\{n_{j \neq i}\}} &=& +\left(\frac{\partial V}{\partial S}\right)_{P,\{n_{j \neq i}\}}  \\
-\frac{\partial^2 A }{\partial T \partial V} &=& +\left(\frac{\partial S}{\partial V}\right)_{T,\{n_{j \neq i}\}} &=& +\left(\frac{\partial P}{\partial T}\right)_{V,\{n_{j \neq i}\}}  \\
\frac{\partial^2 G }{\partial T \partial P} &=& -\left(\frac{\partial S}{\partial P}\right)_{T,\{n_{j \neq i}\}} &=& +\left(\frac{\partial V}{\partial T}\right)_{P,\{n_{j \neq i}\}}
\end{aligned}
\label{eq:maxrelf}
\end{equation}

The relations in \eqref{eq:maxrelf} are called \textbf{Maxwell relation},\footnote{Maxwell relations should not be confused with the Maxwell equations of electromagnetism.} and are useful in experimental settings to relate quantities that are hard to measure with others that are more intuitive.

\begin{quote}
\begin{exercise}
\protect\hypertarget{exr:maxwellEx}{}{\label{exr:maxwellEx} }Derive the last Maxwell relation in eq. \eqref{eq:maxrelf}.

\emph{Solution:} We can start our derivation from the definition of \(V\) and \(S\) as a partial derivative of \(G\):

\begin{equation}
\begin{aligned}
 V &= \left(\frac{\partial G}{\partial P} \right)_{T,\{n_i\}} \qquad \text{and:} \qquad S &= -\left(\frac{\partial G}{\partial T} \right)_{V,\{n_i\}}
\end{aligned}
\end{equation}

and then take a second partial derivative of each quantity with respect to the second variable:

\begin{equation}
\begin{aligned}
 \left(\frac{\partial V}{\partial T} \right)_{P,\{n_i\}} &=\frac{\partial}{\partial T}\left[ \left(\frac{\partial G}{\partial P} \right)_{T,\{n_i\}} \right]_{P,\{n_i\}} \\
\\
-\left(\frac{\partial S}{\partial P} \right)_{T,\{n_i\}} &=\frac{\partial}{\partial P}\left[ \left(\frac{\partial G}{\partial T} \right)_{P,\{n_i\}} \right]_{T,\{n_i\}} \;.
\end{aligned}
\end{equation}

These two derivatives are mixed partial second derivatives of \(G\) with respect to \(T\) and \(P\), and therefore, according to Schwartz's theorem, they are equal to each other:

\begin{equation}
\begin{aligned}
\frac{\partial}{\partial T}\left[ \left(\frac{\partial G}{\partial P} \right)_{T,\{n_i\}} \right]_{P,\{n_i\}} &=
\frac{\partial}{\partial P}\left[ \left(\frac{\partial G}{\partial T} \right)_{P,\{n_i\}} \right]_{T,\{n_i\}} \\
\\
\text{hence:} \\
\\
 \left(\frac{\partial V}{\partial T} \right)_{P,\{n_i\}} &= -\left(\frac{\partial S}{\partial P} \right)_{T,\{n_i\}},
\end{aligned}
\end{equation}

which is the last of Maxwell's relation, as defined in eq. \eqref{eq:maxrelf}. This relation is particularly useful because it connects the quantity \(\left(\frac{\partial S}{\partial P} \right)_{T,\{n_i\}}\)---which is impossible to measure in a lab---with the quantity \(\left(\frac{\partial V}{\partial T} \right)_{P,\{n_i\}}\)---which is easier to measure from an experiment that determines isobaric volumetric thermal expansion coefficients.
\end{exercise}
\end{quote}

\renewcommand*{\standardstate}{{-\kern-6pt{\ominus}\kern-6pt-}}

\hypertarget{ChemicalEquilibrium}{%
\chapter{Chemical Equilibrium}\label{ChemicalEquilibrium}}

In this chapter, we will concentrate on chemical processes that happen at constant \(T\) and constant \(P\).\footnote{The majority of chemical reactions in a lab happens at those condition, and all biological functions happen at those conditions as well.} As such, we will focus our attention on the Gibbs free energy.

\hypertarget{gibbseqsec}{%
\section{Gibbs Equation}\label{gibbseqsec}}

Recalling from the previous chapter, the definition of \(G\) is:

\begin{equation}
G = U -TS -PV = H-TS,
\label{eq:dgdeftot}
\end{equation}

which, taking the differential at constant \(T\) and \(P\), becomes:

\begin{equation}
\begin{aligned}
dG &= dU \; \overbrace{-SdT}^{=0} -TdS \; \overbrace{-VdP}^{=0} -PdV = dH \; \overbrace{-SdT}^{=0} -TdS \\
   &= dH -TdS.
\end{aligned}
\label{eq:dgdeftot2}
\end{equation}

Integrating eq. \label{eq:dgdeftot2} between the initial and final states of a process results in:

\begin{equation}
\begin{aligned}
\int_i^f dG &= \int_i^f dH -T \int_i^f dS \\
\Delta G &= \Delta H -T \Delta S
\end{aligned}
\label{eq:gibbseq}
\end{equation}

which is the famous \textbf{Gibbs equation} for \(\Delta G\). Using Definition \ref{def:helmgibbsminimum}, we can use \(\Delta G\) to infer the spontaneity of a chemical process that happens at constant \(T\) and \(P\) using \(\Delta G \leq 0\). If we set ourselves at standard conditions, we can calculate \(\Delta_{\text{rxn}} G^{-\kern-6pt{\ominus}\kern-6pt-}\) for any reaction as:

\begin{equation}
\begin{aligned}
\Delta_{\text{rxn}} G^{-\kern-6pt{\ominus}\kern-6pt-}&= \Delta_{\text{rxn}} H^{-\kern-6pt{\ominus}\kern-6pt-}-T \Delta_{\text{rxn}} S^{-\kern-6pt{\ominus}\kern-6pt-}\\
&= \sum_i \nu_i \Delta_{\mathrm{f}} H_i^{-\kern-6pt{\ominus}\kern-6pt-}+ T \sum_i \nu_i S_i^{-\kern-6pt{\ominus}\kern-6pt-},
\end{aligned}
\label{eq:gibbseq2}
\end{equation}

where \(\Delta_{\mathrm{f}} H_i^{-\kern-6pt{\ominus}\kern-6pt-}\) are the standard enthalpies of formation, \(S_i^{-\kern-6pt{\ominus}\kern-6pt-}\) are the standard entropies, and \(\nu_i\) are the stoichiometric coefficients for every species \(i\) involved in the reaction. All these quantities are commonly available, and we have already discussed their usage in Chapters \ref{Thermochemistry} and \ref{thirdlaw}, respectively.\footnote{It is not uncommon to see values of \(\Delta_{\text{f}} G^{-\kern-6pt{\ominus}\kern-6pt-}\) tabulated alongside \(\Delta_{\mathrm{f}} H^{-\kern-6pt{\ominus}\kern-6pt-}\) and \(S_i^{-\kern-6pt{\ominus}\kern-6pt-}\), which simplifies even further the calculation. If \(\Delta_{\text{f}} G^{-\kern-6pt{\ominus}\kern-6pt-}\) are not reported, they can always be calculated by their constituents.}

The following four possibilities are possible for \(\Delta G^{-\kern-6pt{\ominus}\kern-6pt-}\) of a chemical reaction:

\begin{longtable}[]{@{}clccc@{}}
\toprule
\begin{minipage}[b]{0.15\columnwidth}\centering
\(\Delta G^{-\kern-6pt{\ominus}\kern-6pt-}\)\strut
\end{minipage} & \begin{minipage}[b]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\centering
\(\Delta H^{-\kern-6pt{\ominus}\kern-6pt-}\)\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\centering
\(\Delta S^{-\kern-6pt{\ominus}\kern-6pt-}\)\strut
\end{minipage} & \begin{minipage}[b]{0.38\columnwidth}\centering
Spontaneous?\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.15\columnwidth}\centering
--\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\emph{if}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
-\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
+\strut
\end{minipage} & \begin{minipage}[t]{0.38\columnwidth}\centering
\emph{Always}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\centering
+\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\emph{if}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
+\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
-\strut
\end{minipage} & \begin{minipage}[t]{0.38\columnwidth}\centering
\emph{Never}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\centering
-/+\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\emph{if}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
-\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
-\strut
\end{minipage} & \begin{minipage}[t]{0.38\columnwidth}\centering
\emph{Depends on \(T\):} \(\scriptstyle{\text{spontaneous at low } T}\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\centering
+/-\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\emph{if}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
+\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
+\strut
\end{minipage} & \begin{minipage}[t]{0.38\columnwidth}\centering
\emph{Depends on \(T\):} \(\scriptstyle{\text{spontaneous at high } T}\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Or, in other words:

\begin{itemize}
\tightlist
\item
  Exothermic reactions that increase the entropy are always spontaneous.
\item
  Endothermic reactions that reduce the entropy are always non-spontaneous.
\item
  For the other two cases, the spontaneity of the reaction depends on the temperature:

  \begin{itemize}
  \tightlist
  \item
    Exothermic reactions that reduce the entropy are spontaneous at low \(T\).
  \item
    Endothermic reactions that increase the entropy are spontaneous at high \(T\).
  \end{itemize}
\end{itemize}

A simple criterion to evaluate the entropic contribution of a reaction is to look at the total number of moles of the reactants and the products (as the sum of the stoichiometric coefficients). If the reaction is producing more molecules than it destroys \(\left( \left| \sum_\text{products} \nu_i \right| > \left| \sum_\text{reactants} \nu_i \right| \right)\), it will increase the entropy. Vice versa, if the total number of moles in a reaction is reducing \(\left( \left| \sum_\text{products} \nu_i \right| < \left| \sum_\text{reactants} \nu_i \right| \right)\), the entropy will also reduce.

\hypertarget{Gbehavior}{%
\section{Behavior of the Gibbs Free Energy}\label{Gbehavior}}

\hypertarget{pressure-dependence-of-delta-g}{%
\subsection{\texorpdfstring{Pressure dependence of \(\Delta G\)}{Pressure dependence of \textbackslash Delta G}}\label{pressure-dependence-of-delta-g}}

\hypertarget{temperature-dependence-of-delta-g}{%
\subsection{\texorpdfstring{Temperature dependence of \(\Delta G\)}{Temperature dependence of \textbackslash Delta G}}\label{temperature-dependence-of-delta-g}}

\hypertarget{composition-dependence-of-delta-g}{%
\subsection{\texorpdfstring{Composition dependence of \(\Delta G\)}{Composition dependence of \textbackslash Delta G}}\label{composition-dependence-of-delta-g}}

\hypertarget{dependence-of-chemical-potentials-on-pressure}{%
\subsubsection{Dependence of chemical potentials on pressure}\label{dependence-of-chemical-potentials-on-pressure}}

\hypertarget{chemeq}{%
\section{Chemical Equilibrium}\label{chemeq}}

\hypertarget{RealGases}{%
\chapter{Real Gases}\label{RealGases}}

\hypertarget{PhaseEquilibrium}{%
\chapter{Phase Equilibrium}\label{PhaseEquilibrium}}

\hypertarget{MCPhaseDiagrams}{%
\chapter{Multi-Component Phase Diagrams}\label{MCPhaseDiagrams}}

\hypertarget{Solutions}{%
\chapter{Solutions}\label{Solutions}}

\hypertarget{KTG}{%
\chapter{Kinetic Theory of Gas}\label{KTG}}

\hypertarget{Kinetics}{%
\chapter{Chemical Kinetics}\label{Kinetics}}

  \bibliography{book.bib,packages.bib}

\end{document}
